{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXQSNvKSqARE"
   },
   "source": [
    "### Importar MedMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8ZhRGJBHVzl8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\hugof\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\hugof\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hugof\\anaconda3\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement t-ensorboard (from versions: none)\n",
      "ERROR: No matching distribution found for t-ensorboard\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.4.3-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from albumentations) (1.11.4)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from albumentations) (0.22.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from albumentations) (4.9.0)\n",
      "Collecting scikit-learn>=1.3.2 (from albumentations)\n",
      "  Downloading scikit_learn-1.4.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting opencv-python-headless>=4.9.0 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (10.2.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.2->albumentations) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.2->albumentations) (2.2.0)\n",
      "Downloading albumentations-1.4.3-py3-none-any.whl (137 kB)\n",
      "   ---------------------------------------- 0.0/137.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 137.0/137.0 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading opencv_python_headless-4.9.0.80-cp37-abi3-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.6/38.5 MB 75.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 6.0/38.5 MB 64.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 9.0/38.5 MB 63.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 11.7/38.5 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 13.9/38.5 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 16.7/38.5 MB 54.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 19.7/38.5 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 22.7/38.5 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 25.7/38.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 28.9/38.5 MB 73.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.2/38.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.6/38.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 50.4 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.4.2-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 4.6/10.6 MB 98.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.3/10.6 MB 98.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 81.8 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python-headless, scikit-learn, albumentations\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "Successfully installed albumentations-1.4.3 opencv-python-headless-4.9.0.80 scikit-learn-1.4.2\n",
      "Collecting fastai\n",
      "  Downloading fastai-2.7.14-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: pip in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fastai) (23.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fastai) (23.1)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai)\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting fastcore<1.6,>=1.5.29 (from fastai)\n",
      "  Downloading fastcore-1.5.29-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting torchvision>=0.11 (from fastai)\n",
      "  Downloading torchvision-0.17.2-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fastai) (3.8.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fastai) (2.1.4)\n",
      "Requirement already satisfied: requests in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fastai) (2.31.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fastai) (6.0.1)\n",
      "Collecting fastprogress>=0.2.4 (from fastai)\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fastai) (10.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fastai) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fastai) (1.11.4)\n",
      "Collecting spacy<4 (from fastai)\n",
      "  Downloading spacy-3.7.4-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torch<2.3,>=1.10 (from fastai)\n",
      "  Downloading torch-2.2.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<4->fastai)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<4->fastai)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<4->fastai)\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<4->fastai)\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<4->fastai)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<4->fastai)\n",
      "  Downloading thinc-8.2.3-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<4->fastai)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<4->fastai)\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<4->fastai)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy<4->fastai)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy<4->fastai)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (4.65.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (68.2.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<4->fastai)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from requests->fastai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from requests->fastai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from requests->fastai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from requests->fastai) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch<2.3,>=1.10->fastai) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch<2.3,>=1.10->fastai) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch<2.3,>=1.10->fastai) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch<2.3,>=1.10->fastai) (3.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch<2.3,>=1.10->fastai) (2023.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from pandas->fastai) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from pandas->fastai) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<4->fastai)\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy<4->fastai)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4->fastai) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<4->fastai) (8.1.7)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy<4->fastai)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from jinja2->spacy<4->fastai) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from sympy->torch<2.3,>=1.10->fastai) (1.3.0)\n",
      "Downloading fastai-2.7.14-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/232.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 232.2/232.2 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading fastcore-1.5.29-py3-none-any.whl (67 kB)\n",
      "   ---------------------------------------- 0.0/67.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 67.6/67.6 kB ? eta 0:00:00\n",
      "Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Downloading spacy-3.7.4-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.7/12.1 MB 53.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.9/12.1 MB 74.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/12.1 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 81.8 MB/s eta 0:00:00\n",
      "Downloading torch-2.2.2-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "   ---------------------------------------- 0.0/198.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 4.7/198.6 MB 99.6 MB/s eta 0:00:02\n",
      "   - ------------------------------------- 10.1/198.6 MB 108.2 MB/s eta 0:00:02\n",
      "   --- ----------------------------------- 15.5/198.6 MB 110.0 MB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 20.8/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   ----- --------------------------------- 26.4/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   ------ -------------------------------- 31.7/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   ------- ------------------------------- 35.8/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------ 41.1/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   --------- ----------------------------- 46.6/198.6 MB 131.2 MB/s eta 0:00:02\n",
      "   ---------- ---------------------------- 52.0/198.6 MB 131.2 MB/s eta 0:00:02\n",
      "   ----------- --------------------------- 57.3/198.6 MB 131.2 MB/s eta 0:00:02\n",
      "   ------------ -------------------------- 62.8/198.6 MB 129.5 MB/s eta 0:00:02\n",
      "   ------------- ------------------------- 68.2/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------ 73.6/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   --------------- ----------------------- 79.0/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------------- ---------------------- 84.3/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   ----------------- --------------------- 89.6/198.6 MB 108.8 MB/s eta 0:00:02\n",
      "   ------------------ -------------------- 95.0/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------- ------------------ 100.3/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------- ----------------- 105.7/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------- ---------------- 111.1/198.6 MB 110.0 MB/s eta 0:00:01\n",
      "   ---------------------- --------------- 116.4/198.6 MB 110.0 MB/s eta 0:00:01\n",
      "   ----------------------- -------------- 121.8/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------ ------------- 127.2/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------- ------------ 132.7/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------- ----------- 138.0/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------------- ---------- 143.3/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------------------------- --------- 148.7/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   ----------------------------- -------- 154.0/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------ ------- 159.5/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------- ------ 165.0/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ----- 170.5/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ---- 175.5/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- --- 181.0/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- -- 186.3/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ - 191.2/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------------  196.4/198.6 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------------------  198.6/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------------  198.6/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------------  198.6/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------------  198.6/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------------  198.6/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------------  198.6/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------------  198.6/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------------  198.6/198.6 MB 131.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 198.6/198.6 MB 22.6 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.17.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 72.2 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 181.6/181.6 kB ? eta 0:00:00\n",
      "Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB ? eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 479.7/479.7 kB ? eta 0:00:00\n",
      "Downloading thinc-8.2.3-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 98.0 MB/s eta 0:00:00\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 4.7/6.6 MB 100.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 104.6 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.0/45.0 kB ? eta 0:00:00\n",
      "Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, murmurhash, langcodes, fastprogress, fastcore, cloudpathlib, catalogue, blis, typer, torch, srsly, preshed, fastdownload, torchvision, confection, weasel, thinc, spacy, fastai\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 fastai-2.7.14 fastcore-1.5.29 fastdownload-0.0.7 fastprogress-1.0.3 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 torch-2.2.2 torchvision-0.17.2 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n",
      "Collecting lightning-bolts\n",
      "  Downloading lightning_bolts-0.7.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightning-bolts) (1.26.4)\n",
      "Collecting pytorch-lightning<2.0.0,>1.7.0 (from lightning-bolts)\n",
      "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting torchmetrics (from lightning-bolts)\n",
      "  Downloading torchmetrics-1.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting lightning-utilities>0.3.1 (from lightning-bolts)\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: torchvision>=0.10.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightning-bolts) (0.17.2)\n",
      "Collecting tensorboard>=2.9.1 (from lightning-bolts)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightning-utilities>0.3.1->lightning-bolts) (23.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightning-utilities>0.3.1->lightning-bolts) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightning-utilities>0.3.1->lightning-bolts) (4.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (6.0.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2023.10.0)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->lightning-bolts)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=2.9.1->lightning-bolts)\n",
      "  Downloading grpcio-1.62.1-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->lightning-bolts) (3.4.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->lightning-bolts) (3.20.3)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->lightning-bolts) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->lightning-bolts)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->lightning-bolts) (2.2.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torchvision>=0.10.0->lightning-bolts) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.1.3)\n",
      "Requirement already satisfied: requests in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.9.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->lightning-bolts) (2.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.3.0)\n",
      "Downloading lightning_bolts-0.7.0-py3-none-any.whl (300 kB)\n",
      "   ---------------------------------------- 0.0/300.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 300.8/300.8 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
      "   ---------------------------------------- 0.0/829.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 829.5/829.5 kB 54.6 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 4.6/5.5 MB 97.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 87.0 MB/s eta 0:00:00\n",
      "Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
      "   ---------------------------------------- 0.0/841.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 841.5/841.5 kB ? eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB ? eta 0:00:00\n",
      "Downloading grpcio-1.62.1-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.8/3.8 MB 80.4 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: tensorboard-data-server, lightning-utilities, grpcio, absl-py, tensorboard, torchmetrics, pytorch-lightning, lightning-bolts\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.62.1 lightning-bolts-0.7.0 lightning-utilities-0.11.2 pytorch-lightning-1.9.5 tensorboard-2.16.2 tensorboard-data-server-0.7.2 torchmetrics-1.3.2\n",
      "Collecting secure-smtplib\n",
      "  Downloading secure_smtplib-0.1.1-py2.py3-none-any.whl.metadata (511 bytes)\n",
      "Downloading secure_smtplib-0.1.1-py2.py3-none-any.whl (3.4 kB)\n",
      "Installing collected packages: secure-smtplib\n",
      "Successfully installed secure-smtplib-0.1.1\n",
      "Collecting lightly\n",
      "  Downloading lightly-1.5.2-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly) (2024.2.2)\n",
      "Collecting hydra-core>=1.0.0 (from lightly)\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lightly-utils~=0.0.0 (from lightly)\n",
      "  Downloading lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly) (2.31.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly) (1.16.0)\n",
      "Requirement already satisfied: tqdm>=4.44 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly) (4.65.0)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly) (2.0.7)\n",
      "Requirement already satisfied: pydantic<2,>=1.10.5 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly) (1.10.12)\n",
      "Collecting aenum>=3.1.11 (from lightly)\n",
      "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly) (2.2.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly) (0.17.2)\n",
      "Requirement already satisfied: pytorch-lightning>=1.0.4 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly) (1.9.5)\n",
      "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.0.0->lightly)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "     ---------------------------------------- 0.0/117.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 117.0/117.0 kB 6.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: packaging in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from hydra-core>=1.0.0->lightly) (23.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightly-utils~=0.0.0->lightly) (10.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from pydantic<2,>=1.10.5->lightly) (4.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from pytorch-lightning>=1.0.4->lightly) (6.0.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (2023.10.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from pytorch-lightning>=1.0.4->lightly) (1.3.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from pytorch-lightning>=1.0.4->lightly) (0.11.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from requests>=2.23.0->lightly) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from requests>=2.23.0->lightly) (3.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch->lightly) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch->lightly) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch->lightly) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch->lightly) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from tqdm>=4.44->lightly) (0.4.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (3.9.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.6.0.post0->pytorch-lightning>=1.0.4->lightly) (68.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from jinja2->torch->lightly) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from sympy->torch->lightly) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (1.9.3)\n",
      "Downloading lightly-1.5.2-py3-none-any.whl (741 kB)\n",
      "   ---------------------------------------- 0.0/741.0 kB ? eta -:--:--\n",
      "   ------------------------- ------------- 481.3/741.0 kB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 741.0/741.0 kB 15.5 MB/s eta 0:00:00\n",
      "Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
      "   ---------------------------------------- 0.0/137.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 137.6/137.6 kB ? eta 0:00:00\n",
      "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "   ---------------------------------------- 0.0/154.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 154.5/154.5 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "   ---------------------------------------- 0.0/79.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 79.5/79.5 kB ? eta 0:00:00\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144578 sha256=6e0bab33e75dbdcb58a29587da35dc74158814b2bfad86e4b5c7564d6b5a1317\n",
      "  Stored in directory: c:\\users\\hugof\\appdata\\local\\pip\\cache\\wheels\\1a\\97\\32\\461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, aenum, omegaconf, lightly-utils, hydra-core, lightly\n",
      "Successfully installed aenum-3.1.15 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 lightly-1.5.2 lightly-utils-0.0.2 omegaconf-2.3.0\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\hugof\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hugof\\anaconda3\\lib\\site-packages (0.17.2)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------  4.1/4.1 MB 86.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.1/4.1 MB 86.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp311-cp311-win_amd64.whl (2454.8 MB)\n",
      "     ---------------------------------------- 0.0/2.5 GB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.5 GB 98.5 MB/s eta 0:00:25\n",
      "     ---------------------------------------- 0.0/2.5 GB 88.3 MB/s eta 0:00:28\n",
      "     ---------------------------------------- 0.0/2.5 GB 93.0 MB/s eta 0:00:27\n",
      "     ---------------------------------------- 0.0/2.5 GB 108.8 MB/s eta 0:00:23\n",
      "     ---------------------------------------- 0.0/2.5 GB 110.0 MB/s eta 0:00:23\n",
      "     ---------------------------------------- 0.0/2.5 GB 110.0 MB/s eta 0:00:23\n",
      "      --------------------------------------- 0.0/2.5 GB 108.8 MB/s eta 0:00:23\n",
      "      --------------------------------------- 0.0/2.5 GB 108.8 MB/s eta 0:00:23\n",
      "      --------------------------------------- 0.0/2.5 GB 108.8 MB/s eta 0:00:23\n",
      "      --------------------------------------- 0.1/2.5 GB 108.8 MB/s eta 0:00:23\n",
      "      --------------------------------------- 0.1/2.5 GB 131.2 MB/s eta 0:00:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 131.2 MB/s eta 0:00:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 131.2 MB/s eta 0:00:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 131.2 MB/s eta 0:00:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 129.5 MB/s eta 0:00:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 131.2 MB/s eta 0:00:19\n",
      "     - -------------------------------------- 0.1/2.5 GB 110.0 MB/s eta 0:00:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 108.8 MB/s eta 0:00:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 108.8 MB/s eta 0:00:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 108.8 MB/s eta 0:00:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 108.8 MB/s eta 0:00:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 108.8 MB/s eta 0:00:22\n",
      "     - -------------------------------------- 0.1/2.5 GB 108.8 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 0.1/2.5 GB 110.0 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 0.1/2.5 GB 110.0 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 0.1/2.5 GB 108.8 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 0.1/2.5 GB 131.2 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 0.1/2.5 GB 131.2 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 0.2/2.5 GB 131.2 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 0.2/2.5 GB 131.2 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 0.2/2.5 GB 108.8 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 108.8 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     -- ------------------------------------- 0.2/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     -- ------------------------------------- 0.2/2.5 GB 110.0 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 110.0 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 110.0 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 110.0 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     ---- ----------------------------------- 0.2/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 108.8 MB/s eta 0:00:21\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 110.0 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 110.0 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 110.0 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 131.2 MB/s eta 0:00:17\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 129.5 MB/s eta 0:00:17\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 131.2 MB/s eta 0:00:17\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 110.0 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 131.2 MB/s eta 0:00:17\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 131.2 MB/s eta 0:00:17\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ------ --------------------------------- 0.4/2.5 GB 110.0 MB/s eta 0:00:19\n",
      "     ------ --------------------------------- 0.4/2.5 GB 110.0 MB/s eta 0:00:19\n",
      "     ------ --------------------------------- 0.4/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ------ --------------------------------- 0.4/2.5 GB 108.8 MB/s eta 0:00:20\n",
      "     ------ --------------------------------- 0.4/2.5 GB 108.8 MB/s eta 0:00:19\n",
      "     ------ --------------------------------- 0.4/2.5 GB 108.8 MB/s eta 0:00:19\n",
      "     ------ --------------------------------- 0.4/2.5 GB 108.8 MB/s eta 0:00:19\n",
      "     ------ --------------------------------- 0.4/2.5 GB 108.8 MB/s eta 0:00:19\n",
      "     ------ --------------------------------- 0.4/2.5 GB 110.0 MB/s eta 0:00:19\n",
      "     ------ --------------------------------- 0.4/2.5 GB 110.0 MB/s eta 0:00:19\n",
      "     ------ --------------------------------- 0.4/2.5 GB 129.5 MB/s eta 0:00:16\n",
      "     ------ --------------------------------- 0.4/2.5 GB 131.2 MB/s eta 0:00:16\n",
      "     ------- -------------------------------- 0.4/2.5 GB 131.2 MB/s eta 0:00:16\n",
      "     ------- -------------------------------- 0.4/2.5 GB 131.2 MB/s eta 0:00:16\n",
      "     ------- -------------------------------- 0.4/2.5 GB 131.2 MB/s eta 0:00:16\n",
      "     ------- -------------------------------- 0.4/2.5 GB 131.2 MB/s eta 0:00:16\n",
      "     ------- -------------------------------- 0.5/2.5 GB 108.8 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 0.5/2.5 GB 108.8 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 0.5/2.5 GB 108.8 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 0.5/2.5 GB 110.0 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 0.5/2.5 GB 110.0 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 0.5/2.5 GB 108.8 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 0.5/2.5 GB 108.8 MB/s eta 0:00:19\n",
      "     ------- -------------------------------- 0.5/2.5 GB 108.8 MB/s eta 0:00:19\n",
      "     -------- ------------------------------- 0.5/2.5 GB 108.8 MB/s eta 0:00:19\n",
      "     -------- ------------------------------- 0.5/2.5 GB 108.8 MB/s eta 0:00:18\n",
      "     -------- ------------------------------- 0.5/2.5 GB 108.8 MB/s eta 0:00:18\n",
      "     -------- ------------------------------- 0.5/2.5 GB 110.0 MB/s eta 0:00:18\n",
      "     -------- ------------------------------- 0.5/2.5 GB 110.0 MB/s eta 0:00:18\n",
      "     -------- ------------------------------- 0.5/2.5 GB 129.5 MB/s eta 0:00:15\n",
      "     -------- ------------------------------- 0.5/2.5 GB 131.2 MB/s eta 0:00:15\n",
      "     -------- ------------------------------- 0.5/2.5 GB 131.2 MB/s eta 0:00:15\n",
      "     -------- ------------------------------- 0.5/2.5 GB 131.2 MB/s eta 0:00:15\n",
      "     -------- ------------------------------- 0.5/2.5 GB 131.2 MB/s eta 0:00:15\n",
      "     -------- ------------------------------- 0.5/2.5 GB 131.2 MB/s eta 0:00:15\n",
      "     --------- ------------------------------ 0.6/2.5 GB 131.2 MB/s eta 0:00:15\n",
      "     --------- ------------------------------ 0.6/2.5 GB 131.2 MB/s eta 0:00:15\n",
      "     --------- ------------------------------ 0.6/2.5 GB 108.8 MB/s eta 0:00:18\n",
      "     --------- ------------------------------ 0.6/2.5 GB 110.0 MB/s eta 0:00:18\n",
      "     --------- ------------------------------ 0.6/2.5 GB 110.0 MB/s eta 0:00:18\n",
      "     --------- ------------------------------ 0.6/2.5 GB 108.8 MB/s eta 0:00:18\n",
      "     --------- ------------------------------ 0.6/2.5 GB 108.8 MB/s eta 0:00:18\n",
      "     --------- ------------------------------ 0.6/2.5 GB 108.8 MB/s eta 0:00:18\n",
      "     --------- ------------------------------ 0.6/2.5 GB 108.8 MB/s eta 0:00:18\n",
      "     --------- ------------------------------ 0.6/2.5 GB 108.8 MB/s eta 0:00:18\n",
      "     --------- ------------------------------ 0.6/2.5 GB 108.8 MB/s eta 0:00:17\n",
      "     --------- ------------------------------ 0.6/2.5 GB 110.0 MB/s eta 0:00:17\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 110.0 MB/s eta 0:00:17\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 108.8 MB/s eta 0:00:17\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 108.8 MB/s eta 0:00:17\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 108.8 MB/s eta 0:00:17\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 131.2 MB/s eta 0:00:14\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 131.2 MB/s eta 0:00:14\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 131.2 MB/s eta 0:00:14\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 131.2 MB/s eta 0:00:14\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 131.2 MB/s eta 0:00:14\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 129.5 MB/s eta 0:00:14\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 110.0 MB/s eta 0:00:17\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 110.0 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 108.8 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 108.8 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 108.8 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 108.8 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 108.8 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 108.8 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 110.0 MB/s eta 0:00:16\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 110.0 MB/s eta 0:00:16\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 108.8 MB/s eta 0:00:16\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 108.8 MB/s eta 0:00:16\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 108.8 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 0.7/2.5 GB 108.8 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 0.7/2.5 GB 131.2 MB/s eta 0:00:14\n",
      "     ------------ --------------------------- 0.7/2.5 GB 108.8 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 0.8/2.5 GB 110.0 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 0.8/2.5 GB 110.0 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 0.8/2.5 GB 129.5 MB/s eta 0:00:14\n",
      "     ------------ --------------------------- 0.8/2.5 GB 131.2 MB/s eta 0:00:13\n",
      "     ------------ --------------------------- 0.8/2.5 GB 131.2 MB/s eta 0:00:13\n",
      "     ------------ --------------------------- 0.8/2.5 GB 131.2 MB/s eta 0:00:13\n",
      "     ------------ --------------------------- 0.8/2.5 GB 131.2 MB/s eta 0:00:13\n",
      "     ------------ --------------------------- 0.8/2.5 GB 131.2 MB/s eta 0:00:13\n",
      "     ------------ --------------------------- 0.8/2.5 GB 108.8 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 0.8/2.5 GB 108.8 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 0.8/2.5 GB 108.8 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 0.8/2.5 GB 110.0 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 0.8/2.5 GB 110.0 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 0.8/2.5 GB 108.8 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 0.8/2.5 GB 108.8 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 0.8/2.5 GB 108.8 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 0.8/2.5 GB 108.8 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 0.8/2.5 GB 108.8 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 0.8/2.5 GB 108.8 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 0.9/2.5 GB 110.0 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 0.9/2.5 GB 110.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 108.8 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 108.8 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 108.8 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 108.8 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 131.2 MB/s eta 0:00:12\n",
      "     -------------- ------------------------- 0.9/2.5 GB 131.2 MB/s eta 0:00:12\n",
      "     -------------- ------------------------- 0.9/2.5 GB 110.0 MB/s eta 0:00:15\n",
      "     -------------- ------------------------- 0.9/2.5 GB 131.2 MB/s eta 0:00:12\n",
      "     -------------- ------------------------- 0.9/2.5 GB 129.5 MB/s eta 0:00:12\n",
      "     -------------- ------------------------- 0.9/2.5 GB 131.2 MB/s eta 0:00:12\n",
      "     -------------- ------------------------- 0.9/2.5 GB 131.2 MB/s eta 0:00:12\n",
      "     --------------- ------------------------ 0.9/2.5 GB 131.2 MB/s eta 0:00:12\n",
      "     --------------- ------------------------ 0.9/2.5 GB 131.2 MB/s eta 0:00:12\n",
      "     --------------- ------------------------ 0.9/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 0.9/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 0.9/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 0.9/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 1.0/2.5 GB 110.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 1.0/2.5 GB 110.0 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 1.0/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 1.0/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 1.0/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     --------------- ------------------------ 1.0/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 110.0 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 110.0 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 108.8 MB/s eta 0:00:14\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 131.2 MB/s eta 0:00:11\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 131.2 MB/s eta 0:00:11\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 131.2 MB/s eta 0:00:11\n",
      "     ----------------- ---------------------- 1.0/2.5 GB 131.2 MB/s eta 0:00:11\n",
      "     ----------------- ---------------------- 1.0/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 110.0 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 110.0 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 110.0 MB/s eta 0:00:13\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 110.0 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 1.1/2.5 GB 108.8 MB/s eta 0:00:13\n",
      "     ------------------ --------------------- 1.1/2.5 GB 110.0 MB/s eta 0:00:12\n",
      "     ------------------ --------------------- 1.1/2.5 GB 131.2 MB/s eta 0:00:11\n",
      "     ------------------ --------------------- 1.1/2.5 GB 129.5 MB/s eta 0:00:11\n",
      "     ------------------ --------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     ------------------ --------------------- 1.2/2.5 GB 108.8 MB/s eta 0:00:12\n",
      "     ------------------ --------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     ------------------- -------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     ------------------- -------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     ------------------- -------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     ------------------- -------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     ------------------- -------------------- 1.2/2.5 GB 129.5 MB/s eta 0:00:10\n",
      "     ------------------- -------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     ------------------- -------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     ------------------- -------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     ------------------- -------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     ------------------- -------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     ------------------- -------------------- 1.2/2.5 GB 131.2 MB/s eta 0:00:10\n",
      "     -------------------- ------------------- 1.2/2.5 GB 108.8 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 1.2/2.5 GB 108.8 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 1.2/2.5 GB 81.8 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 1.2/2.5 GB 59.5 MB/s eta 0:00:21\n",
      "     -------------------- ------------------- 1.2/2.5 GB 46.7 MB/s eta 0:00:27\n",
      "     -------------------- ------------------- 1.2/2.5 GB 38.5 MB/s eta 0:00:32\n",
      "     -------------------- ------------------- 1.2/2.5 GB 36.4 MB/s eta 0:00:34\n",
      "     -------------------- ------------------- 1.2/2.5 GB 34.4 MB/s eta 0:00:36\n",
      "     -------------------- ------------------- 1.2/2.5 GB 108.8 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 1.3/2.5 GB 108.8 MB/s eta 0:00:12\n",
      "     -------------------- ------------------- 1.3/2.5 GB 110.0 MB/s eta 0:00:11\n",
      "     -------------------- ------------------- 1.3/2.5 GB 110.0 MB/s eta 0:00:11\n",
      "     -------------------- ------------------- 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     -------------------- ------------------- 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     -------------------- ------------------- 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     -------------------- ------------------- 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 110.0 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 110.0 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 93.9 MB/s eta 0:00:13\n",
      "     --------------------- ------------------ 1.3/2.5 GB 110.0 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     --------------------- ------------------ 1.3/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:11\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 131.2 MB/s eta 0:00:09\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 110.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 131.2 MB/s eta 0:00:09\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 110.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 110.0 MB/s eta 0:00:10\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 110.0 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 110.0 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 108.8 MB/s eta 0:00:10\n",
      "     ------------------------ --------------- 1.5/2.5 GB 131.2 MB/s eta 0:00:08\n",
      "     ------------------------ --------------- 1.5/2.5 GB 131.2 MB/s eta 0:00:08\n",
      "     ------------------------ --------------- 1.5/2.5 GB 131.2 MB/s eta 0:00:08\n",
      "     ------------------------ --------------- 1.5/2.5 GB 131.2 MB/s eta 0:00:08\n",
      "     ------------------------ --------------- 1.5/2.5 GB 129.5 MB/s eta 0:00:08\n",
      "     ------------------------ --------------- 1.5/2.5 GB 131.2 MB/s eta 0:00:08\n",
      "     ------------------------ --------------- 1.5/2.5 GB 110.0 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 1.5/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 1.5/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 1.5/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 1.5/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------ --------------- 1.5/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------- -------------- 1.5/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------- -------------- 1.5/2.5 GB 110.0 MB/s eta 0:00:09\n",
      "     ------------------------- -------------- 1.5/2.5 GB 110.0 MB/s eta 0:00:09\n",
      "     ------------------------- -------------- 1.6/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------- -------------- 1.6/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------- -------------- 1.6/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------- -------------- 1.6/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------- -------------- 1.6/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------- -------------- 1.6/2.5 GB 108.8 MB/s eta 0:00:09\n",
      "     ------------------------- -------------- 1.6/2.5 GB 110.0 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 1.6/2.5 GB 110.0 MB/s eta 0:00:08\n",
      "     ------------------------- -------------- 1.6/2.5 GB 108.8 MB/s eta 0:00:08\n",
      "     -------------------------- ------------- 1.6/2.5 GB 108.8 MB/s eta 0:00:08\n",
      "     -------------------------- ------------- 1.6/2.5 GB 108.8 MB/s eta 0:00:08\n",
      "     -------------------------- ------------- 1.6/2.5 GB 108.8 MB/s eta 0:00:08\n",
      "     -------------------------- ------------- 1.6/2.5 GB 131.2 MB/s eta 0:00:07\n",
      "     -------------------------- ------------- 1.6/2.5 GB 131.2 MB/s eta 0:00:07\n",
      "     -------------------------- ------------- 1.6/2.5 GB 131.2 MB/s eta 0:00:07\n",
      "     -------------------------- ------------- 1.6/2.5 GB 131.2 MB/s eta 0:00:07\n",
      "     -------------------------- ------------- 1.6/2.5 GB 129.5 MB/s eta 0:00:07\n",
      "     -------------------------- ------------- 1.6/2.5 GB 110.0 MB/s eta 0:00:08\n",
      "     -------------------------- ------------- 1.6/2.5 GB 110.0 MB/s eta 0:00:08\n",
      "     -------------------------- ------------- 1.7/2.5 GB 108.8 MB/s eta 0:00:08\n",
      "     --------------------------- ------------ 1.7/2.5 GB 108.8 MB/s eta 0:00:08\n",
      "     --------------------------- ------------ 1.7/2.5 GB 108.8 MB/s eta 0:00:08\n",
      "     --------------------------- ------------ 1.7/2.5 GB 108.8 MB/s eta 0:00:08\n",
      "     --------------------------- ------------ 1.7/2.5 GB 108.8 MB/s eta 0:00:08\n",
      "     --------------------------- ------------ 1.7/2.5 GB 108.8 MB/s eta 0:00:08\n",
      "     --------------------------- ------------ 1.7/2.5 GB 110.0 MB/s eta 0:00:08\n",
      "     --------------------------- ------------ 1.7/2.5 GB 110.0 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 1.7/2.5 GB 108.8 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 1.7/2.5 GB 108.8 MB/s eta 0:00:07\n",
      "     --------------------------- ------------ 1.7/2.5 GB 131.2 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 1.7/2.5 GB 131.2 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 1.7/2.5 GB 131.2 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 1.7/2.5 GB 131.2 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 1.7/2.5 GB 131.2 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 1.7/2.5 GB 131.2 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 1.7/2.5 GB 108.8 MB/s eta 0:00:07\n",
      "     ---------------------------- ----------- 1.7/2.5 GB 110.0 MB/s eta 0:00:07\n",
      "     ---------------------------- ----------- 1.7/2.5 GB 110.0 MB/s eta 0:00:07\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 108.8 MB/s eta 0:00:07\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 108.8 MB/s eta 0:00:07\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 108.8 MB/s eta 0:00:07\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 108.8 MB/s eta 0:00:07\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 108.8 MB/s eta 0:00:07\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 108.8 MB/s eta 0:00:07\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 110.0 MB/s eta 0:00:07\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 110.0 MB/s eta 0:00:07\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 108.8 MB/s eta 0:00:07\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 108.8 MB/s eta 0:00:07\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 108.8 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 108.8 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 108.8 MB/s eta 0:00:06\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 131.2 MB/s eta 0:00:05\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 131.2 MB/s eta 0:00:05\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 131.2 MB/s eta 0:00:05\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 129.5 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 1.8/2.5 GB 131.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 1.8/2.5 GB 131.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 1.9/2.5 GB 131.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 1.9/2.5 GB 131.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 1.9/2.5 GB 131.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 1.9/2.5 GB 131.2 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 1.9/2.5 GB 108.8 MB/s eta 0:00:06\n",
      "     ------------------------------ --------- 1.9/2.5 GB 108.8 MB/s eta 0:00:06\n",
      "     ------------------------------ --------- 1.9/2.5 GB 110.0 MB/s eta 0:00:06\n",
      "     ------------------------------ --------- 1.9/2.5 GB 110.0 MB/s eta 0:00:06\n",
      "     ------------------------------ --------- 1.9/2.5 GB 108.8 MB/s eta 0:00:06\n",
      "     ------------------------------ --------- 1.9/2.5 GB 108.8 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 1.9/2.5 GB 108.8 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 1.9/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 1.9/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 1.9/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 1.9/2.5 GB 110.0 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 1.9/2.5 GB 110.0 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 1.9/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 1.9/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 1.9/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 2.0/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     ------------------------------- -------- 2.0/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 110.0 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 110.0 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 108.8 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 110.0 MB/s eta 0:00:05\n",
      "     -------------------------------- ------- 2.0/2.5 GB 110.0 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 2.0/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 2.0/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 2.0/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 2.0/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 2.0/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 2.1/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 2.1/2.5 GB 110.0 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 2.1/2.5 GB 110.0 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 2.1/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 2.1/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 2.1/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     --------------------------------- ------ 2.1/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 131.2 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 131.2 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 131.2 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 129.5 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 110.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 110.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 108.8 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 110.0 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 110.0 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 110.0 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 110.0 MB/s eta 0:00:03\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 2.2/2.5 GB 108.8 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 2.2/2.5 GB 110.0 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 2.2/2.5 GB 110.0 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 2.3/2.5 GB 108.8 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 2.3/2.5 GB 108.8 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 2.3/2.5 GB 108.8 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 2.3/2.5 GB 131.2 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 131.2 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 131.2 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 131.2 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 131.2 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 108.8 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 110.0 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 110.0 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 108.8 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 108.8 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 108.8 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 108.8 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 2.3/2.5 GB 108.8 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.3/2.5 GB 108.8 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.3/2.5 GB 110.0 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.3/2.5 GB 110.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 129.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 131.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 131.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 131.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 131.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 93.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 65.6 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.4/2.5 GB 50.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.4/2.5 GB 40.9 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.4/2.5 GB 36.4 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.4/2.5 GB 34.4 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.4/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 131.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.5 GB 110.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.5 GB 110.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 108.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 GB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hugof\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "Successfully installed torch-2.2.2+cu121 torchaudio-2.2.2+cu121\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install tqdm\n",
    "!pip install t-ensorboard\n",
    "!pip install albumentations\n",
    "!pip install fastai\n",
    "!pip install lightning-bolts\n",
    "!pip install secure-smtplib\n",
    "!pip install lightly\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOyyFNG5ah9G"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "gpFl6UPoKfpg",
    "outputId": "82c2ff8e-01c2-43f5-f132-a656523cdefa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugof\\AppData\\Local\\Temp\\ipykernel_15868\\2535912911.py:10: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n",
      "C:\\Users\\hugof\\anaconda3\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "C:\\Users\\hugof\\anaconda3\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "C:\\Users\\hugof\\anaconda3\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "C:\\Users\\hugof\\anaconda3\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "C:\\Users\\hugof\\anaconda3\\Lib\\site-packages\\pl_bolts\\losses\\self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Number of workers: 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## tqdm for loading bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import STL10\n",
    "from torchvision import transforms\n",
    "\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install --quiet pytorch-lightning>=1.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "\n",
    "# Import tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# In this notebook, we use data loaders with heavier computational processing. It is recommended to use as many\n",
    "# workers as possible in a data loader, which corresponds to the number of CPU cores\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "CHECKPOINT_PATH = r\"content/\"\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# upload external file before import\n",
    "#from google.colab import files\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of workers:\", NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 4070'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SDE-fg7lHGTz"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "#import torch\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxHl5KWHHGT2"
   },
   "source": [
    "## Data processing and dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "U7kt6Ee0UFaX"
   },
   "outputs": [],
   "source": [
    "class ContrastiveTransformations(object):\n",
    "\n",
    "    def __init__(self, base_transforms, n_views=2):\n",
    "        self.base_transforms = base_transforms\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.base_transforms(x) for i in range(self.n_views)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Cciglw9fHGh"
   },
   "source": [
    "### Breast Ultrasound Images Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hhIV_rDUqARQ"
   },
   "outputs": [],
   "source": [
    "contrast_transforms_ultra = transforms.Compose([\n",
    "                                          transforms.Resize((500,500)),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomResizedCrop(size=500),\n",
    "                                          transforms.RandomApply([\n",
    "                                              transforms.ColorJitter(brightness=0.5,\n",
    "                                                                     contrast=0.5,\n",
    "                                                                     saturation=0.5,\n",
    "                                                                     hue=0.1)\n",
    "                                          ], p=0.8),\n",
    "                                          transforms.RandomGrayscale(p=0.2),\n",
    "                                          transforms.GaussianBlur(kernel_size=9),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.5,), (0.5,))\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "o-R_GJIIqARQ"
   },
   "outputs": [],
   "source": [
    "img_transforms_ultra = transforms.Compose([\n",
    "                                     transforms.Resize((500,500)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5,), (0.5,))\n",
    "                                     ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xmeEjf8LqARQ"
   },
   "outputs": [],
   "source": [
    "mask_transforms_ultra = transforms.Compose([\n",
    "                                     transforms.Resize((500,500)),\n",
    "                                     transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5Ua2SQS_fLam"
   },
   "outputs": [],
   "source": [
    "class UltrasoundDatasetSSL(Dataset):\n",
    "  def __init__(self, image_dir, transform = None):\n",
    "    self.image_dir = image_dir\n",
    "    self.transform = transform\n",
    "    self.images = os.listdir(image_dir)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    img_path = os.path.join(self.image_dir,self.images[idx])\n",
    "    image = (Image.open(img_path).convert(\"RGB\"))\n",
    "    #image = io.imread(img_path)\n",
    "    #print(\"Mask: \", mask)\n",
    "\n",
    "    if self.transform is not None:\n",
    "      img1,img2 = self.transform(image)\n",
    "\n",
    "    #print(\"Mask: \", mask)\n",
    "\n",
    "    return ([img1,img2], \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryDatasetSSL(Dataset):\n",
    "  def __init__(self, image_dir, transform = None):\n",
    "    self.image_dir = image_dir\n",
    "    self.transform = transform\n",
    "    self.images = os.listdir(image_dir)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    img_path = os.path.join(self.image_dir,self.images[idx])\n",
    "    image = (Image.open(img_path).convert(\"RGB\"))\n",
    "    #image = io.imread(img_path)\n",
    "    #print(\"Mask: \", mask)\n",
    "\n",
    "    if self.transform is not None:\n",
    "      img1 = self.transform(image)\n",
    "\n",
    "    #print(\"Mask: \", mask)\n",
    "\n",
    "    return (img1, \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "neTGG7tOqARR"
   },
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "  def __init__(self, image_dir, mask_dir, label, img_transform = None, mask_transform = None):\n",
    "    self.image_dir = image_dir\n",
    "    self.mask_dir = mask_dir\n",
    "    self.img_transform = img_transform\n",
    "    self.mask_transform = mask_transform\n",
    "    self.images = os.listdir(image_dir)\n",
    "    self.label = label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    img_path = os.path.join(self.image_dir,self.images[idx])\n",
    "    str = self.images[idx]\n",
    "    split = str.split(\".\")\n",
    "    #print(split[0])\n",
    "    mask_name = split[0] + \"_mask.png\"\n",
    "    mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "    #mask[mask>=255.0] = 1.0\n",
    "    #mask = torch.from_numpy(mask)\n",
    "\n",
    "    if self.img_transform is not None:\n",
    "        image = self.img_transform(image)\n",
    "        mask = self.mask_transform(mask)\n",
    "\n",
    "    #print(\"Mask: \", mask)\n",
    "\n",
    "    return image,[mask,self.label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "maoAvF_CrueW"
   },
   "outputs": [],
   "source": [
    "TRAIN_IMG_DIR = \"./Ultrasound_Dataset/Contrastive Learning/train\"\n",
    "VAL_IMG_DIR= \"./Ultrasound_Dataset/Contrastive Learning/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "QDgB3j2pqARS",
    "outputId": "eff905e0-9d4b-4bbf-8a47-71a3d34eb4b1"
   },
   "outputs": [],
   "source": [
    "train_dataset = UltrasoundDatasetSSL(\n",
    "    image_dir = TRAIN_IMG_DIR,\n",
    "    transform = ContrastiveTransformations(contrast_transforms_ultra, n_views=2)\n",
    ")\n",
    "\n",
    "\n",
    "val_dataset = UltrasoundDatasetSSL(\n",
    "    image_dir = VAL_IMG_DIR,\n",
    "    transform = ContrastiveTransformations(contrast_transforms_ultra, n_views=2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BENIGN_IMG = \"./Ultrasound_Dataset/BUS/test/benign/images\"\n",
    "TEST_BENIGN_MASK =\"./Ultrasound_Dataset/BUS/test/benign/masks\"\n",
    "\n",
    "TEST_MALIGNANT_IMG =\"./Ultrasound_Dataset/BUS/test/malignant/images\"\n",
    "TEST_MALIGNANT_MASK =\"./Ultrasound_Dataset/BUS/test/malignant/masks\"\n",
    "\n",
    "TEST_NORMAL_IMG=\"./Ultrasound_Dataset/BUS/test/normal/images\"\n",
    "TEST_NORMAL_MASK=\"./Ultrasound_Dataset/BUS/test/normal/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJvoSj1nqARS"
   },
   "outputs": [],
   "source": [
    "test_benign_dataset = MaskDataset(\n",
    "    image_dir = TEST_BENIGN_IMG,\n",
    "    mask_dir = TEST_BENIGN_MASK,\n",
    "    img_transform = img_transforms_ultra,\n",
    "    mask_transform = mask_transforms_ultra,\n",
    "    label = \"benign\"\n",
    ")\n",
    "\n",
    "test_malignant_dataset = MaskDataset(\n",
    "    image_dir = TEST_MALIGNANT_IMG,\n",
    "    mask_dir = TEST_MALIGNANT_MASK,\n",
    "    img_transform = img_transforms_ultra,\n",
    "    mask_transform = mask_transforms_ultra,\n",
    "    label = \"malignant\"\n",
    ")\n",
    "\n",
    "test_normal_dataset = MaskDataset(\n",
    "    image_dir = TEST_NORMAL_IMG,\n",
    "    mask_dir = TEST_NORMAL_MASK,\n",
    "    img_transform = img_transforms_ultra,\n",
    "    mask_transform = mask_transforms_ultra,\n",
    "    label = \"normal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LBtmLZ5RQnA"
   },
   "outputs": [],
   "source": [
    "test_dataset = torch.utils.data.ConcatDataset([test_benign_dataset, test_malignant_dataset, test_normal_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HW03WjgyheOA"
   },
   "outputs": [],
   "source": [
    "TRAIN_BENIGN_IMG = \"./Ultrasound_Dataset/BUS/train/benign/images\"\n",
    "TRAIN_BENIGN_MASK =\"./Ultrasound_Dataset/BUS/train/benign/masks\"\n",
    "\n",
    "TRAIN_MALIGNANT_IMG =\"./Ultrasound_Dataset/BUS/train/malignant/images\"\n",
    "TRAIN_MALIGNANT_MASK =\"./Ultrasound_Dataset/BUS/train/malignant/masks\"\n",
    "\n",
    "TRAIN_NORMAL_IMG=\"./Ultrasound_Dataset/BUS/train/normal/images\"\n",
    "TRAIN_NORMAL_MASK=\"./Ultrasound_Dataset/BUS/train/normal/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benign_dataset = MaskDataset(\n",
    "    image_dir = TRAIN_BENIGN_IMG,\n",
    "    mask_dir = TRAIN_BENIGN_MASK,\n",
    "    img_transform = img_transforms_ultra,\n",
    "    mask_transform = mask_transforms_ultra,\n",
    "    label = \"benign\"\n",
    ")\n",
    "\n",
    "train_malignant_dataset = MaskDataset(\n",
    "    image_dir = TRAIN_MALIGNANT_IMG,\n",
    "    mask_dir = TRAIN_MALIGNANT_MASK,\n",
    "    img_transform = img_transforms_ultra,\n",
    "    mask_transform = mask_transforms_ultra,\n",
    "    label = \"malignant\"\n",
    ")\n",
    "\n",
    "train_normal_dataset = MaskDataset(\n",
    "    image_dir = TRAIN_NORMAL_IMG,\n",
    "    mask_dir = TRAIN_NORMAL_MASK,\n",
    "    img_transform = img_transforms_ultra,\n",
    "    mask_transform = mask_transforms_ultra,\n",
    "    label = \"normal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.ConcatDataset([train_benign_dataset, train_malignant_dataset, train_normal_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_BENIGN_IMG = \"./Ultrasound_Dataset/BUS/val/benign/images\"\n",
    "VAL_BENIGN_MASK =\"./Ultrasound_Dataset/BUS/val/benign/masks\"\n",
    "\n",
    "VAL_MALIGNANT_IMG =\"./Ultrasound_Dataset/BUS/val/malignant/images\"\n",
    "VAL_MALIGNANT_MASK =\"./Ultrasound_Dataset/BUS/val/malignant/masks\"\n",
    "\n",
    "VAL_NORMAL_IMG=\"./Ultrasound_Dataset/BUS/val/normal/images\"\n",
    "VAL_NORMAL_MASK=\"./Ultrasound_Dataset/BUS/val/normal/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_benign_dataset = MaskDataset(\n",
    "    image_dir = VAL_BENIGN_IMG,\n",
    "    mask_dir = VAL_BENIGN_MASK,\n",
    "    img_transform = img_transforms_ultra,\n",
    "    mask_transform = mask_transforms_ultra,\n",
    "    label = \"benign\"\n",
    ")\n",
    "\n",
    "val_malignant_dataset = MaskDataset(\n",
    "    image_dir = VAL_MALIGNANT_IMG,\n",
    "    mask_dir = VAL_MALIGNANT_MASK,\n",
    "    img_transform = img_transforms_ultra,\n",
    "    mask_transform = mask_transforms_ultra,\n",
    "    label = \"malignant\"\n",
    ")\n",
    "\n",
    "val_normal_dataset = MaskDataset(\n",
    "    image_dir = VAL_NORMAL_IMG,\n",
    "    mask_dir = VAL_NORMAL_MASK,\n",
    "    img_transform = img_transforms_ultra,\n",
    "    mask_transform = mask_transforms_ultra,\n",
    "    label = \"normal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = torch.utils.data.ConcatDataset([val_benign_dataset, val_malignant_dataset, val_normal_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4zBGlH2xBwD"
   },
   "source": [
    "# U-Net Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkWwoAlcxEHo"
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZRNAIZVIc6g"
   },
   "source": [
    "# U-Net normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWjKmBDGym92"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XDMAXg1HWhP"
   },
   "source": [
    "# Unet Simclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vF7EFUSGHamo"
   },
   "outputs": [],
   "source": [
    "class UNet_Simclr(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet_Simclr, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64,512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x6 = self.avgpool(x)\n",
    "        #alterar isto para dar flatten e conseguir\n",
    "        x7 = torch.flatten(x6,1)\n",
    "        x8 = self.fc(x7)\n",
    "        return x8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9Vqavfi5F1_"
   },
   "outputs": [],
   "source": [
    "for (name, module) in unet.named_children():\n",
    "    if name == 'inc' or name == 'down1' or name == 'down2' or name == 'down3' or name == 'down4':\n",
    "        for layer in module.children():\n",
    "            print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nebaFQrltPuv"
   },
   "source": [
    "# U-Net with ResNet Encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetWithResnet50EncoderPretrain(nn.Module):\n",
    "    DEPTH = 6\n",
    "\n",
    "    def __init__(self, n_classes=1):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet.resnet50(pretrained=False)\n",
    "        down_blocks = []\n",
    "        up_blocks = []\n",
    "        self.input_block = nn.Sequential(*list(resnet.children()))[:3]\n",
    "        self.input_pool = list(resnet.children())[3]\n",
    "        for bottleneck in list(resnet.children()):\n",
    "            if isinstance(bottleneck, nn.Sequential):\n",
    "                down_blocks.append(bottleneck)\n",
    "        self.down_blocks = nn.ModuleList(down_blocks)\n",
    "        self.bridge = Bridge(2048, 2048)\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(2048, 1024))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(1024, 512))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(512, 256))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=128 + 64, out_channels=128,\n",
    "                                                    up_conv_in_channels=256, up_conv_out_channels=128))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=64 + 3, out_channels=64,\n",
    "                                                    up_conv_in_channels=128, up_conv_out_channels=64))\n",
    "\n",
    "        self.up_blocks = nn.ModuleList(up_blocks)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(64,512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, with_output_feature_map=False):\n",
    "        pre_pools = dict()\n",
    "        pre_pools[f\"layer_0\"] = x\n",
    "        x = self.input_block(x)\n",
    "        pre_pools[f\"layer_1\"] = x\n",
    "        x = self.input_pool(x)\n",
    "\n",
    "        for i, block in enumerate(self.down_blocks, 2):\n",
    "            x = block(x)\n",
    "            if i == (UNetWithResnet50Encoder.DEPTH - 1):\n",
    "                continue\n",
    "            pre_pools[f\"layer_{i}\"] = x\n",
    "\n",
    "        x = self.bridge(x)\n",
    "\n",
    "        for i, block in enumerate(self.up_blocks, 1):\n",
    "            key = f\"layer_{UNetWithResnet50Encoder.DEPTH - 1 - i}\"\n",
    "            x = block(x, pre_pools[key])\n",
    "        output_feature_map = x\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.out(x)\n",
    "        del pre_pools\n",
    "        if with_output_feature_map:\n",
    "            return x, output_feature_map\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUHI2AVVtV5A"
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Helper module that consists of a Conv -> BN -> ReLU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.with_nonlinearity = with_nonlinearity\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.with_nonlinearity:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bridge(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the middle layer of the UNet which just consists of some\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.bridge = nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels),\n",
    "            ConvBlock(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bridge(x)\n",
    "\n",
    "\n",
    "class UpBlockForUNetWithResNet50(nn.Module):\n",
    "    \"\"\"\n",
    "    Up block that encapsulates one up-sampling step which consists of Upsample -> ConvBlock -> ConvBlock\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n",
    "                 upsampling_method=\"conv_transpose\"):\n",
    "        super().__init__()\n",
    "\n",
    "        if up_conv_in_channels == None:\n",
    "            up_conv_in_channels = in_channels\n",
    "        if up_conv_out_channels == None:\n",
    "            up_conv_out_channels = out_channels\n",
    "\n",
    "        if upsampling_method == \"conv_transpose\":\n",
    "            self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n",
    "        elif upsampling_method == \"bilinear\":\n",
    "            self.upsample = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "            )\n",
    "        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n",
    "        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, up_x, down_x):\n",
    "        \"\"\"\n",
    "\n",
    "        :param up_x: this is the output from the previous up block\n",
    "        :param down_x: this is the output from the down block\n",
    "        :return: upsampled feature map\n",
    "        \"\"\"\n",
    "        x = self.upsample(up_x)\n",
    "        x = torch.cat([x, down_x], 1)\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetWithResnet50Encoder(nn.Module):\n",
    "    DEPTH = 6\n",
    "\n",
    "    def __init__(self, resnet, n_classes=1):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet.resnet50(pretrained=True)\n",
    "        down_blocks = []\n",
    "        up_blocks = []\n",
    "        self.input_block = nn.Sequential(*list(resnet.children()))[:3]\n",
    "        self.input_pool = list(resnet.children())[3]\n",
    "        for bottleneck in list(resnet.children()):\n",
    "            if isinstance(bottleneck, nn.Sequential):\n",
    "                down_blocks.append(bottleneck)\n",
    "        self.down_blocks = nn.ModuleList(down_blocks)\n",
    "        self.bridge = Bridge(2048, 2048)\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(2048, 1024))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(1024, 512))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(512, 256))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=128 + 64, out_channels=128,\n",
    "                                                    up_conv_in_channels=256, up_conv_out_channels=128))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=64 + 3, out_channels=64,\n",
    "                                                    up_conv_in_channels=128, up_conv_out_channels=64))\n",
    "\n",
    "        self.up_blocks = nn.ModuleList(up_blocks)\n",
    "\n",
    "        self.out = nn.Conv2d(64, n_classes, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x, with_output_feature_map=False):\n",
    "        pre_pools = dict()\n",
    "        pre_pools[f\"layer_0\"] = x\n",
    "        x = self.input_block(x)\n",
    "        pre_pools[f\"layer_1\"] = x\n",
    "        x = self.input_pool(x)\n",
    "\n",
    "        for i, block in enumerate(self.down_blocks, 2):\n",
    "            x = block(x)\n",
    "            if i == (UNetWithResnet50Encoder.DEPTH - 1):\n",
    "                continue\n",
    "            pre_pools[f\"layer_{i}\"] = x\n",
    "\n",
    "        x = self.bridge(x)\n",
    "\n",
    "        for i, block in enumerate(self.up_blocks, 1):\n",
    "            key = f\"layer_{UNetWithResnet50Encoder.DEPTH - 1 - i}\"\n",
    "            x = block(x, pre_pools[key])\n",
    "        output_feature_map = x\n",
    "        x = self.out(x)\n",
    "        del pre_pools\n",
    "        if with_output_feature_map:\n",
    "            return x, output_feature_map\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6JzmKiCKel3"
   },
   "source": [
    "# SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CIFAR_BUS = \"./mini-imagenet-2023/mini-imagenet+BUS/train\"\n",
    "VAL_CIFAR_BUS = \"./mini-imagenet-2023/mini-imagenet+BUS/test\"\n",
    "\n",
    "train_dataset = UltrasoundDatasetSSL(os.path.join(TRAIN_CIFAR_BUS), ContrastiveTransformations(contrast_transforms_ultra, n_views=2))\n",
    "val_dataset = UltrasoundDatasetSSL(os.path.join(VAL_CIFAR_BUS), ContrastiveTransformations(contrast_transforms_ultra, n_views=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CIFAR = \"./mini-imagenet-2023/mini-imagenet/train\"\n",
    "VAL_CIFAR = \"./mini-imagenet-2023/mini-imagenet/test\"\n",
    "\n",
    "train_dataset = UltrasoundDatasetSSL(os.path.join(TRAIN_CIFAR), ContrastiveTransformations(contrast_transforms_ultra, n_views=2))\n",
    "val_dataset = UltrasoundDatasetSSL(os.path.join(VAL_CIFAR), ContrastiveTransformations(contrast_transforms_ultra, n_views=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oi3R-g54UFae"
   },
   "outputs": [],
   "source": [
    "class SimCLR1(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=20000):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "        # Base model f(.)\n",
    "        self.convnet = torchvision.models.resnet50(pretrained=False,\n",
    "                                                   num_classes=4*hidden_dim) # Output of last linear layer\n",
    "        ##self.convnet = encoder\n",
    "        #resnet = torchvision.models.resnet50(pretrained=False)\n",
    "        #self.convnet = UNetWithResnet50EncoderPretrain(resnet)\n",
    "        #self.convnet  = torchvision.models.vit_b_16(pretrained = False, num_classes = 4 * hidden_dim)\n",
    "        #self.convnet = UNet(3,1,True)\n",
    "        #self.convnet.outc = nn.Sequential(\n",
    "        #    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        #    nn.Flatten(),\n",
    "        #    nn.Linear(64,512),\n",
    "        #    nn.ReLU(inplace=True),\n",
    "        #    nn.Linear(512, 128, bias=False)\n",
    "        #)\n",
    "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(),\n",
    "                                lr=self.hparams.lr,\n",
    "                                weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                            T_max=self.hparams.max_epochs,\n",
    "                                                            eta_min=self.hparams.lr/50)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def info_nce_loss(self, batch, mode='train'):\n",
    "        imgs, _ = batch\n",
    "        imgs = torch.cat(imgs, dim=0)\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.convnet(imgs)\n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = F.cosine_similarity(feats[:,None,:], feats[None,:,:], dim=-1)\n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0]//2, dims=0)\n",
    "        # InfoNCE loss\n",
    "        cos_sim = cos_sim / self.hparams.temperature\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Logging loss\n",
    "        self.log(mode+'_loss', nll)\n",
    "        # Get ranking position of positive example\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:,None],  # First position positive example\n",
    "                              cos_sim.masked_fill(pos_mask, -9e15)],\n",
    "                             dim=-1)\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "        # Logging ranking metrics\n",
    "        self.log(mode+'_acc_top1', (sim_argsort == 0).float().mean())\n",
    "        self.log(mode+'_acc_top5', (sim_argsort < 5).float().mean())\n",
    "        self.log(mode+'_acc_mean_pos', 1+sim_argsort.float().mean())\n",
    "\n",
    "        return nll\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.info_nce_loss(batch, mode='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.info_nce_loss(batch, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52N8vAqdNROL"
   },
   "outputs": [],
   "source": [
    "TRAIN_BENIGN_IMG = \"./Ultrasound_Dataset/BUS/train/benign/images\"\n",
    "TRAIN_BENIGN_MASK =\"./Ultrasound_Dataset/BUS/train/benign/masks\"\n",
    "\n",
    "TRAIN_MALIGNANT_IMG =\"./Ultrasound_Dataset/BUS/train/malignant/images\"\n",
    "TRAIN_MALIGNANT_MASK =\"./Ultrasound_Dataset/BUS/train/malignant/masks\"\n",
    "\n",
    "TRAIN_NORMAL_IMG=\"./Ultrasound_Dataset/BUS/train/normal/images\"\n",
    "TRAIN_NORMAL_MASK=\"./Ultrasound_Dataset/BUS/train/normal/masks\"\n",
    "\n",
    "\n",
    "train_benign_simclr = UltrasoundDatasetSSL(os.path.join(TRAIN_BENIGN_IMG), ContrastiveTransformations(contrast_transforms_ultra, n_views=2))\n",
    "train_malignant_simclr = UltrasoundDatasetSSL(os.path.join(TRAIN_MALIGNANT_IMG), ContrastiveTransformations(contrast_transforms_ultra, n_views=2))\n",
    "train_normal_simclr = UltrasoundDatasetSSL(os.path.join(TRAIN_NORMAL_IMG), ContrastiveTransformations(contrast_transforms_ultra, n_views=2))\n",
    "\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_benign_simclr, train_malignant_simclr, train_normal_simclr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_BENIGN_IMG = \"./Ultrasound_Dataset/BUS/val/benign/images\"\n",
    "VAL_BENIGN_MASK =\"./Ultrasound_Dataset/BUS/val/benign/masks\"\n",
    "\n",
    "VAL_MALIGNANT_IMG =\"./Ultrasound_Dataset/BUS/val/malignant/images\"\n",
    "VAL_MALIGNANT_MASK =\"./Ultrasound_Dataset/BUS/val/malignant/masks\"\n",
    "\n",
    "VAL_NORMAL_IMG=\"./Ultrasound_Dataset/BUS/val/normal/images\"\n",
    "VAL_NORMAL_MASK=\"./Ultrasound_Dataset/BUS/val/normal/masks\"\n",
    "\n",
    "\n",
    "val_benign_simclr = UltrasoundDatasetSSL(os.path.join(VAL_BENIGN_IMG), ContrastiveTransformations(contrast_transforms_ultra, n_views=2))\n",
    "val_malignant_simclr = UltrasoundDatasetSSL(os.path.join(VAL_MALIGNANT_IMG), ContrastiveTransformations(contrast_transforms_ultra, n_views=2))\n",
    "val_normal_simclr = UltrasoundDatasetSSL(os.path.join(VAL_NORMAL_IMG), ContrastiveTransformations(contrast_transforms_ultra, n_views=2))\n",
    "\n",
    "val_dataset = torch.utils.data.ConcatDataset([val_benign_simclr, val_malignant_simclr, val_normal_simclr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wDwt9g0jUFaf"
   },
   "outputs": [],
   "source": [
    "def train_simclr(batch_size, max_epochs=100, **kwargs):\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_acc_top5\", min_delta=0.01, patience=5, verbose=True, mode=\"max\")\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join('./Trained Models-500/SimCLR', 'BUS'),\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         log_every_n_steps=3,\n",
    "                         max_epochs=max_epochs,\n",
    "                         max_time={\"days\": 2},\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode='max', monitor='val_acc_top5'),\n",
    "                                    LearningRateMonitor('epoch'), early_stop_callback])\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join('./Trained Models/SimCLR/ViT_b_16/lightning_logs/version_7/checkpoints/eda')\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f'Found pretrained model at {pretrained_filename}, loading...')\n",
    "        model = SimCLR.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
    "        train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                       drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "        val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                     drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "        pl.seed_everything(42) # To be reproducable\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = SimCLR.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "\n",
    "    else:\n",
    "        train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                       drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "        val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                     drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "        pl.seed_everything(42) # To be reproducable\n",
    "        model = SimCLR1(max_epochs=max_epochs, **kwargs)\n",
    "        #print(model)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = SimCLR1.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QYp6GxMDpWfJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "/home/hugo-figueiras/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hugo-figueiras/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | convnet | ResNet | 24.6 M\n",
      "-----------------------------------\n",
      "24.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.6 M    Total params\n",
      "98.491    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo-figueiras/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:85: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81c2124b6774829a04bd5de355fa5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved. New best score: 0.399\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.026 >= min_delta = 0.01. New best score: 0.425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.139 >= min_delta = 0.01. New best score: 0.564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.194 >= min_delta = 0.01. New best score: 0.758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.086 >= min_delta = 0.01. New best score: 0.843\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.030 >= min_delta = 0.01. New best score: 0.873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.030 >= min_delta = 0.01. New best score: 0.904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.012 >= min_delta = 0.01. New best score: 0.916\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.014 >= min_delta = 0.01. New best score: 0.930\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.011 >= min_delta = 0.01. New best score: 0.941\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.013 >= min_delta = 0.01. New best score: 0.954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.012 >= min_delta = 0.01. New best score: 0.965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc_top5 improved by 0.011 >= min_delta = 0.01. New best score: 0.976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time limit reached. Elapsed time is 2 days, 0:00:00. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simclr_model = train_simclr(batch_size=32,\n",
    "                            hidden_dim=128,\n",
    "                            lr=0.003,\n",
    "                            temperature=0.07,\n",
    "                            weight_decay=1e-4,\n",
    "                            max_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYZkCU-5ZbLz"
   },
   "source": [
    "# MoCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAsrQyyxZd6_"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from torchvision.datasets import CIFAR10, ImageFolder\n",
    "from torchvision.models import resnet\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5lX-6VBh_sT"
   },
   "source": [
    "### Set arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UAUIII93h7Ys",
    "outputId": "73a31e75-0d9a-4084-d927-40a525ce48ee"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Train MoCo')\n",
    "\n",
    "parser.add_argument('-a', '--arch', default='resnet50')\n",
    "\n",
    "# lr: 0.06 for batch 512 (or 0.03 for batch 256)\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.03, type=float, metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--epochs', default=20000, type=int, metavar='N', help='number of total epochs to run')\n",
    "parser.add_argument('--schedule', default=[120, 160], nargs='*', type=int, help='learning rate schedule (when to drop lr by 10x); does not take effect if --cos is on')\n",
    "parser.add_argument('--cos', action='store_true', help='use cosine lr schedule')\n",
    "\n",
    "parser.add_argument('--batch-size', default=64, type=int, metavar='N', help='mini-batch size')\n",
    "parser.add_argument('--wd', default=5e-4, type=float, metavar='W', help='weight decay')\n",
    "\n",
    "# moco specific configs:\n",
    "parser.add_argument('--moco-dim', default=128, type=int, help='feature dimension')\n",
    "parser.add_argument('--moco-k', default=4096, type=int, help='queue size; number of negative keys')\n",
    "parser.add_argument('--moco-m', default=0.99, type=float, help='moco momentum of updating key encoder')\n",
    "parser.add_argument('--moco-t', default=0.1, type=float, help='softmax temperature')\n",
    "\n",
    "parser.add_argument('--bn-splits', default=8, type=int, help='simulate multi-gpu behavior of BatchNorm in one gpu; 1 is SyncBatchNorm in multi-gpu')\n",
    "\n",
    "parser.add_argument('--symmetric', action='store_true', help='use a symmetric loss function that backprops to both crops')\n",
    "\n",
    "# knn monitor\n",
    "parser.add_argument('--knn-k', default=12, type=int, help='k in kNN monitor')\n",
    "parser.add_argument('--knn-t', default=0.1, type=float, help='softmax temperature in kNN monitor; could be different with moco-t')\n",
    "\n",
    "# utils\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH', help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--results-dir', default='', type=str, metavar='PATH', help='path to cache (default: none)')\n",
    "\n",
    "'''\n",
    "args = parser.parse_args()  # running in command line\n",
    "'''\n",
    "args = parser.parse_args('')  # running in ipynb\n",
    "\n",
    "# set command line arguments here when running in ipynb\n",
    "args.epochs = 20000\n",
    "args.cos = True\n",
    "args.schedule = []  # cos in use\n",
    "args.symmetric = False\n",
    "if args.results_dir == '':\n",
    "    args.results_dir = './MoCo-Multi-ResNet50-64'\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0uwlQFSiC7f"
   },
   "source": [
    "### Define data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-JE_eUZiJif"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((50,50)),\n",
    "    transforms.RandomResizedCrop(50),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((50,50)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upcWniRphdxd"
   },
   "outputs": [],
   "source": [
    "MULTI_TRAIN = \"./Ultrasound_Dataset/Contrastive Learning/train\"\n",
    "MULTI_TEST = \"./Ultrasound_Dataset/Contrastive Learning/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_moco = UltrasoundDatasetSSL(os.path.join(MULTI_TRAIN), ContrastiveTransformations(train_transform, n_views=2))\n",
    "val_moco = UltrasoundDatasetSSL(os.path.join(MULTI_TRAIN), ContrastiveTransformations(train_transform, n_views=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_moco = data.DataLoader(train_moco, batch_size=args.batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "test_loader_moco = data.DataLoader(val_moco, batch_size=args.batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BENIGN_IMG = \"./Ultrasound_Dataset/BUS/train/benign/images\"\n",
    "TRAIN_BENIGN_MASK =\"./Ultrasound_Dataset/BUS/train/benign/masks\"\n",
    "\n",
    "TRAIN_MALIGNANT_IMG =\"./Ultrasound_Dataset/BUS/train/malignant/images\"\n",
    "TRAIN_MALIGNANT_MASK =\"./Ultrasound_Dataset/BUS/train/malignant/masks\"\n",
    "\n",
    "TRAIN_NORMAL_IMG=\"./Ultrasound_Dataset/BUS/train/normal/images\"\n",
    "TRAIN_NORMAL_MASK=\"./Ultrasound_Dataset/BUS/train/normal/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_BENIGN_IMG = \"./Ultrasound_Dataset/BUS/val/benign/images\"\n",
    "VAL_BENIGN_MASK =\"./Ultrasound_Dataset/BUS/val/benign/masks\"\n",
    "\n",
    "VAL_MALIGNANT_IMG =\"./Ultrasound_Dataset/BUS/val/malignant/images\"\n",
    "VAL_MALIGNANT_MASK =\"./Ultrasound_Dataset/BUS/val/malignant/masks\"\n",
    "\n",
    "VAL_NORMAL_IMG=\"./Ultrasound_Dataset/BUS/val/normal/images\"\n",
    "VAL_NORMAL_MASK=\"./Ultrasound_Dataset/BUS/val/normal/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymDBSDsofzcD"
   },
   "outputs": [],
   "source": [
    "train_benign_moco = UltrasoundDatasetSSL(os.path.join(TRAIN_BENIGN_IMG), ContrastiveTransformations(train_transform, n_views=2))\n",
    "train_malignant_moco = UltrasoundDatasetSSL(os.path.join(TRAIN_MALIGNANT_IMG), ContrastiveTransformations(train_transform, n_views=2))\n",
    "train_normal_moco = UltrasoundDatasetSSL(os.path.join(TRAIN_NORMAL_IMG), ContrastiveTransformations(train_transform, n_views=2))\n",
    "\n",
    "memory_benign_moco = MemoryDatasetSSL(os.path.join(TRAIN_BENIGN_IMG), test_transform)\n",
    "memory_malignant_moco = MemoryDatasetSSL(os.path.join(TRAIN_MALIGNANT_IMG), test_transform)\n",
    "memory_normal_moco = MemoryDatasetSSL(os.path.join(TRAIN_NORMAL_IMG), test_transform)\n",
    "\n",
    "test_benign_moco = MemoryDatasetSSL(os.path.join(VAL_BENIGN_IMG), ContrastiveTransformations(train_transform, n_views=2))\n",
    "test_malignant_moco = MemoryDatasetSSL(os.path.join(VAL_MALIGNANT_IMG), ContrastiveTransformations(train_transform, n_views=2))\n",
    "test_normal_moco = MemoryDatasetSSL(os.path.join(VAL_NORMAL_IMG), ContrastiveTransformations(train_transform, n_views=2))\n",
    "\n",
    "train_dataset_moco = torch.utils.data.ConcatDataset([train_benign_moco, train_malignant_moco, train_normal_moco])\n",
    "memory_dataset_moco = torch.utils.data.ConcatDataset([memory_benign_moco, memory_malignant_moco, memory_normal_moco])\n",
    "test_dataset_moco = torch.utils.data.ConcatDataset([test_benign_moco, test_malignant_moco, test_normal_moco])\n",
    "\n",
    "\n",
    "\n",
    "train_loader_moco = data.DataLoader(train_dataset_moco, batch_size=args.batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "memory_loader_moco = data.DataLoader(memory_dataset_moco, batch_size=args.batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader_moco = data.DataLoader(test_dataset_moco, batch_size=64, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CIFAR_BUS = \"./mini-imagenet-2023/mini-imagenet+BUS/train\"\n",
    "VAL_CIFAR_BUS = \"./mini-imagenet-2023/mini-imagenet+BUS/test\"\n",
    "\n",
    "train_cifar_bus_moco = UltrasoundDatasetSSL(os.path.join(TRAIN_CIFAR_BUS), ContrastiveTransformations(train_transform, n_views=2))\n",
    "memory_cifar_bus_moco = MemoryDatasetSSL(os.path.join(TRAIN_CIFAR_BUS), test_transform)\n",
    "test_cifar_bus_moco = MemoryDatasetSSL(os.path.join(VAL_CIFAR_BUS), ContrastiveTransformations(train_transform, n_views=2))\n",
    "\n",
    "train_loader_moco = data.DataLoader(train_cifar_bus_moco, batch_size=args.batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "memory_loader_moco = data.DataLoader(memory_cifar_bus_moco, batch_size=args.batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader_moco = data.DataLoader(test_cifar_bus_moco, batch_size=args.batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CIFAR = \"./mini-imagenet-2023/mini-imagenet/train\"\n",
    "VAL_CIFAR = \"./mini-imagenet-2023/mini-imagenet/test\"\n",
    "\n",
    "train_cifar_moco = UltrasoundDatasetSSL(os.path.join(TRAIN_CIFAR), ContrastiveTransformations(train_transform, n_views=2))\n",
    "memory_cifar_moco = MemoryDatasetSSL(os.path.join(TRAIN_CIFAR), test_transform)\n",
    "test_cifar_moco = MemoryDatasetSSL(os.path.join(VAL_CIFAR), ContrastiveTransformations(train_transform, n_views=2))\n",
    "\n",
    "train_loader_moco = data.DataLoader(train_cifar_moco, batch_size=args.batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "memory_loader_moco = data.DataLoader(memory_cifar_moco, batch_size=args.batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader_moco = data.DataLoader(test_cifar_moco, batch_size=args.batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsAVAtRoiBbG"
   },
   "source": [
    "### Define base encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNd_Q_Osi0SO"
   },
   "outputs": [],
   "source": [
    "# SplitBatchNorm: simulate multi-gpu behavior of BatchNorm in one gpu by splitting alone the batch dimension\n",
    "# implementation adapted from https://github.com/davidcpage/cifar10-fast/blob/master/torch_backend.py\n",
    "class SplitBatchNorm(nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, num_splits, **kw):\n",
    "        super().__init__(num_features, **kw)\n",
    "        self.num_splits = num_splits\n",
    "\n",
    "    def forward(self, input):\n",
    "        #print(input.shape)\n",
    "        N, C, H, W = input.shape\n",
    "        if self.training or not self.track_running_stats:\n",
    "            running_mean_split = self.running_mean.repeat(self.num_splits)\n",
    "            running_var_split = self.running_var.repeat(self.num_splits)\n",
    "            outcome = nn.functional.batch_norm(\n",
    "    \n",
    "                input.view(-1, C * self.num_splits, H, W), running_mean_split, running_var_split,\n",
    "                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
    "                True, self.momentum, self.eps).view(N, C, H, W)\n",
    "            self.running_mean.data.copy_(running_mean_split.view(self.num_splits, C).mean(dim=0))\n",
    "            self.running_var.data.copy_(running_var_split.view(self.num_splits, C).mean(dim=0))\n",
    "            return outcome\n",
    "        else:\n",
    "            return nn.functional.batch_norm(\n",
    "                input, self.running_mean, self.running_var,\n",
    "                self.weight, self.bias, False, self.momentum, self.eps)\n",
    "\n",
    "class ModelBase(nn.Module):\n",
    "    \"\"\"\n",
    "    Common CIFAR ResNet recipe.\n",
    "    Comparing with ImageNet ResNet recipe, it:\n",
    "    (i) replaces conv1 with kernel=3, str=1\n",
    "    (ii) removes pool1\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim=128, arch=None, bn_splits=16):\n",
    "        super(ModelBase, self).__init__()\n",
    "\n",
    "        # use split batchnorm\n",
    "        norm_layer = partial(SplitBatchNorm, num_splits=bn_splits) if bn_splits > 1 else nn.BatchNorm2d\n",
    "        resnet_arch = getattr(resnet, arch)\n",
    "        net = resnet_arch(pretrained=False,num_classes=feature_dim, norm_layer=norm_layer)\n",
    "\n",
    "        self.net = []\n",
    "        for name, module in net.named_children():\n",
    "            if name == 'conv1':\n",
    "                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            if isinstance(module, nn.MaxPool2d):\n",
    "                continue\n",
    "            if isinstance(module, nn.Linear):\n",
    "                self.net.append(nn.Flatten(1))\n",
    "            self.net.append(module)\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        # note: not normalized here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJFOHlOBpLay"
   },
   "source": [
    "### Define MoCo wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lzFyFnhbk8hj",
    "outputId": "f07893b9-93ba-4b45-c337-77d5cb1ee2d3"
   },
   "outputs": [],
   "source": [
    "class ModelMoCo(nn.Module):\n",
    "    def __init__(self, dim=128, K=4096, m=0.99, T=0.1, arch='resnet50', bn_splits=8, symmetric=True):\n",
    "        super(ModelMoCo, self).__init__()\n",
    "\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.symmetric = symmetric\n",
    "\n",
    "        # create the encoders\n",
    "        self.encoder_q = ModelBase(feature_dim=dim, arch=arch, bn_splits=bn_splits)\n",
    "        #unet_q = UNet(3,1,True)\n",
    "        #unet_q.outc = nn.Sequential(\n",
    "        #    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        #    nn.Flatten(),\n",
    "        #    nn.Linear(64,512),\n",
    "        #    nn.ReLU(inplace=True),\n",
    "        #    nn.Linear(512, 128, bias=False)\n",
    "        #)\n",
    "        #self.encoder_q = unet_q\n",
    "        #self.encoder_q = convnet\n",
    "        self.encoder_k = ModelBase(feature_dim=dim, arch=arch, bn_splits=bn_splits)\n",
    "        #unet_k = UNet(3,1,True)\n",
    "        #unet_k.outc = nn.Sequential(\n",
    "        #    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        #    nn.Flatten(),\n",
    "        #    nn.Linear(64,512),\n",
    "        #    nn.ReLU(inplace=True),\n",
    "        #    nn.Linear(512, 128, bias=False)\n",
    "        #)\n",
    "        #self.encoder_k = unet_k\n",
    "        #self.encoder_k = UNetWithResnet50EncoderPretrain()\n",
    "        #self.encoder_k = convnet\n",
    "\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient\n",
    "\n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.K % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.t()  # transpose\n",
    "        ptr = (ptr + batch_size) % self.K  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_single_gpu(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle, for making use of BatchNorm.\n",
    "        \"\"\"\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(x.shape[0]).cuda()\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        return x[idx_shuffle], idx_unshuffle\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_single_gpu(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle.\n",
    "        \"\"\"\n",
    "        return x[idx_unshuffle]\n",
    "\n",
    "    def contrastive_loss(self, im_q, im_k):\n",
    "        # compute query features\n",
    "        q = self.encoder_q(im_q)  # queries: NxC\n",
    "        q = nn.functional.normalize(q, dim=1)  # already normalized\n",
    "\n",
    "        # compute key features\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            # shuffle for making use of BN\n",
    "            im_k_, idx_unshuffle = self._batch_shuffle_single_gpu(im_k)\n",
    "\n",
    "            k = self.encoder_k(im_k_)  # keys: NxC\n",
    "            k = nn.functional.normalize(k, dim=1)  # already normalized\n",
    "\n",
    "            # undo shuffle\n",
    "            k = self._batch_unshuffle_single_gpu(k, idx_unshuffle)\n",
    "\n",
    "        # compute logits\n",
    "        # Einstein sum is more intuitive\n",
    "        # positive logits: Nx1\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
    "        # negative logits: NxK\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
    "\n",
    "        # logits: Nx(1+K)\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= self.T\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "\n",
    "        loss = nn.CrossEntropyLoss().cuda()(logits, labels)\n",
    "\n",
    "        return loss, q, k\n",
    "\n",
    "    def forward(self, im1, im2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            im_q: a batch of query images\n",
    "            im_k: a batch of key images\n",
    "        Output:\n",
    "            loss\n",
    "        \"\"\"\n",
    "\n",
    "        # update the key encoder\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            self._momentum_update_key_encoder()\n",
    "\n",
    "        # compute loss\n",
    "        if self.symmetric:  # asymmetric loss\n",
    "            loss_12, q1, k2 = self.contrastive_loss(im1, im2)\n",
    "            loss_21, q2, k1 = self.contrastive_loss(im2, im1)\n",
    "            loss = loss_12 + loss_21\n",
    "            k = torch.cat([k1, k2], dim=0)\n",
    "        else:  # asymmetric loss\n",
    "            loss, q, k = self.contrastive_loss(im1, im2)\n",
    "\n",
    "        self._dequeue_and_enqueue(k)\n",
    "\n",
    "        return loss\n",
    "\n",
    "# create model\n",
    "#model = ModelMoCo(\n",
    "#        dim=args.moco_dim,\n",
    "#        K=args.moco_k,\n",
    "#        m=args.moco_m,\n",
    "#        T=args.moco_t,\n",
    "#        arch=args.arch,\n",
    "#        bn_splits=args.bn_splits,\n",
    "#        symmetric=args.symmetric,\n",
    "#    ).cuda()\n",
    "#print(model.encoder_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YXcpXBwi8KV"
   },
   "source": [
    "### Define train/test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBKFqboqnqty"
   },
   "outputs": [],
   "source": [
    "# train for one epoch\n",
    "def train(net, data_loader, train_optimizer, epoch, args):\n",
    "    net.train()\n",
    "    adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
    "    for imgs, labes in train_bar:\n",
    "        im_1 = imgs[0]\n",
    "        im_2 = imgs[1]\n",
    "        im_1, im_2 = im_1.cuda(non_blocking=True), im_2.cuda(non_blocking=True)\n",
    "\n",
    "        loss = net(im_1, im_2)\n",
    "\n",
    "        train_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_optimizer.step()\n",
    "\n",
    "        total_num += data_loader.batch_size\n",
    "        total_loss += loss.item() * data_loader.batch_size\n",
    "        train_bar.set_description('Train Epoch: [{}/{}], lr: {:.6f}, Loss: {:.4f}'.format(epoch, args.epochs, optimizer.param_groups[0]['lr'], total_loss / total_num))\n",
    "\n",
    "    return total_loss / total_num\n",
    "\n",
    "# lr scheduler for training\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    lr = args.lr\n",
    "    if args.cos:  # cosine lr schedule\n",
    "        lr *= 0.5 * (1. + math.cos(math.pi * epoch / args.epochs))\n",
    "    else:  # stepwise lr schedule\n",
    "        for milestone in args.schedule:\n",
    "            lr *= 0.1 if epoch >= milestone else 1.\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "RI1Y8bSImD7N"
   },
   "outputs": [],
   "source": [
    "# test using a knn monitor\n",
    "def test(net, data_loader, train_optimizer, epoch, args):\n",
    "    net.eval()\n",
    "\n",
    "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
    "    for imgs, labes in train_bar:\n",
    "        im_1 = imgs[0]\n",
    "        im_2 = imgs[1]\n",
    "        im_1, im_2 = im_1.cuda(non_blocking=True), im_2.cuda(non_blocking=True)\n",
    "\n",
    "        loss = net(im_1, im_2)\n",
    "\n",
    "        train_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_optimizer.step()\n",
    "\n",
    "        total_num += data_loader.batch_size\n",
    "        total_loss += loss.item() * data_loader.batch_size\n",
    "        train_bar.set_description('Val Epoch: [{}/{}], lr: {:.6f}, Loss: {:.4f}'.format(epoch, args.epochs, optimizer.param_groups[0]['lr'], total_loss / total_num))\n",
    "\n",
    "    return total_loss / total_num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86lHkiKox3KO"
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.wd, momentum=0.9)\n",
    "\n",
    "# load model if resume\n",
    "epoch_start = 1\n",
    "if args.resume is not '':\n",
    "    checkpoint = torch.load(args.resume)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    epoch_start = checkpoint['epoch'] + 1\n",
    "    print('Loaded from: {}'.format(args.resume))\n",
    "\n",
    "# logging\n",
    "results = {'train_loss': [], 'test_acc@1': []}\n",
    "if not os.path.exists(args.results_dir):\n",
    "    os.mkdir(args.results_dir)\n",
    "# dump args\n",
    "with open(args.results_dir + '/args.json', 'w') as fid:\n",
    "    json.dump(args.__dict__, fid, indent=2)\n",
    "\n",
    "loss_counter=100.00\n",
    "count=0\n",
    "    \n",
    "# training loop\n",
    "for epoch in range(epoch_start, args.epochs + 1):\n",
    "    if count == 50:\n",
    "        torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer' : optimizer.state_dict(),}, args.results_dir + '/model_last.pth')\n",
    "        break\n",
    "    train_loss = train(model, train_loader_moco, optimizer, epoch, args)\n",
    "    results['train_loss'].append(train_loss)\n",
    "    if epoch%5==0 and epoch > 50:\n",
    "        test_acc_1 = test(model, test_loader_moco, optimizer, epoch, args)\n",
    "        results['test_acc@1'].append(test_acc_1)\n",
    "    # save statistics\n",
    "    #data_frame = pd.DataFrame(data=results, index=range(epoch_start, epoch + 1))\n",
    "    #data_frame.to_csv(args.results_dir + '/log.csv', index_label='epoch')\n",
    "    # save model\n",
    "        if test_acc_1 < loss_counter:\n",
    "            if loss_counter - test_acc_1 > 0.01 :\n",
    "                count=0\n",
    "                loss_counter=test_acc_1\n",
    "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer' : optimizer.state_dict(),}, args.results_dir + '/model_best.pth')\n",
    "            else:\n",
    "                count=count+1\n",
    "        else:\n",
    "            count=count+1\n",
    "    torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer' : optimizer.state_dict(),}, args.results_dir + '/model_last.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimSiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightly.data import LightlyDataset\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models.modules.heads import SimSiamPredictionHead, SimSiamProjectionHead\n",
    "from lightly.transforms import SimCLRTransform, utils\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data =\"./Ultrasound_Dataset/Contrastive Learning/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "seed = 1\n",
    "epochs = 100\n",
    "input_size = 50\n",
    "\n",
    "# dimension of the embeddings\n",
    "num_ftrs = 2048\n",
    "# dimension of the output of the prediction and projection heads\n",
    "out_dim = proj_hidden_dim = 2048\n",
    "# the prediction head uses a bottleneck architecture\n",
    "pred_hidden_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the augmentations for self-supervised learning\n",
    "transform = SimCLRTransform(\n",
    "    input_size=input_size,\n",
    "    # require invariance to flips and rotations\n",
    "    hf_prob=0.5,\n",
    "    vf_prob=0.5,\n",
    "    rr_prob=0.5,\n",
    "    # satellite images are all taken from the same height\n",
    "    # so we use only slight random cropping\n",
    "    min_scale=0.5,\n",
    "    # use a weak color jitter for invariance w.r.t small color changes\n",
    "    cj_prob=0.2,\n",
    "    cj_bright=0.1,\n",
    "    cj_contrast=0.1,\n",
    "    cj_hue=0.1,\n",
    "    cj_sat=0.1,\n",
    ")\n",
    "\n",
    "# create a lightly dataset for training with augmentations\n",
    "dataset_train_simsiam = LightlyDataset(input_dir=path_to_data, transform=transform)\n",
    "\n",
    "# create a dataloader for training\n",
    "dataloader_train_simsiam = torch.utils.data.DataLoader(\n",
    "    dataset_train_simsiam,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "# create a torchvision transformation for embedding the dataset after training\n",
    "# here, we resize the images to match the input size during training and apply\n",
    "# a normalization of the color channel based on statistics from imagenet\n",
    "test_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((input_size, input_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=utils.IMAGENET_NORMALIZE[\"mean\"],\n",
    "            std=utils.IMAGENET_NORMALIZE[\"std\"],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create a lightly dataset for embedding\n",
    "dataset_test = LightlyDataset(input_dir=path_to_data, transform=test_transforms)\n",
    "\n",
    "# create a dataloader for embedding\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_simsiam_b = LightlyDataset(input_dir=TRAIN_BENIGN_IMG, transform=transform)\n",
    "dataset_train_simsiam_m = LightlyDataset(input_dir=TRAIN_MALIGNANT_IMG, transform=transform)\n",
    "dataset_train_simsiam_n = LightlyDataset(input_dir=TRAIN_NORMAL_IMG, transform=transform)\n",
    "\n",
    "dataset_train_simsiam = torch.utils.data.ConcatDataset([dataset_train_simsiam_b, dataset_train_simsiam_m, dataset_train_simsiam_n])\n",
    "\n",
    "dataloader_train_simsiam = torch.utils.data.DataLoader(\n",
    "    dataset_train_simsiam,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    def __init__(self, backbone, num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = SimSiamProjectionHead(num_ftrs, proj_hidden_dim, out_dim)\n",
    "        self.prediction_head = SimSiamPredictionHead(out_dim, pred_hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get representations\n",
    "        f = self.backbone(x).flatten(start_dim=1)\n",
    "        # get projections\n",
    "        z = self.projection_head(f)\n",
    "        # get predictions\n",
    "        p = self.prediction_head(z)\n",
    "        # stop gradient\n",
    "        z = z.detach()\n",
    "        return z, p\n",
    "\n",
    "\n",
    "# we use a pretrained resnet for this tutorial to speed\n",
    "# up training time but you can also train one from scratch\n",
    "\n",
    "backbone = torchvision.models.resnet.resnet50(pretrained=False)\n",
    "model = SimSiam(backbone, num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimSiam uses a symmetric negative cosine similarity loss\n",
    "criterion = NegativeCosineSimilarity()\n",
    "\n",
    "# scale the learning rate\n",
    "lr = 0.05 * batch_size / 256\n",
    "# use SGD with momentum and weight decay\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "avg_loss = 0.0\n",
    "avg_output_std = 0.0\n",
    "for e in range(epochs):\n",
    "    for (x0, x1), _, _ in dataloader_train_simsiam:\n",
    "        # move images to the gpu\n",
    "        x0 = x0.to(device)\n",
    "        x1 = x1.to(device)\n",
    "\n",
    "        # run the model on both transforms of the images\n",
    "        # we get projections (z0 and z1) and\n",
    "        # predictions (p0 and p1) as output\n",
    "        z0, p0 = model(x0)\n",
    "        z1, p1 = model(x1)\n",
    "\n",
    "        # apply the symmetric negative cosine similarity\n",
    "        # and run backpropagation\n",
    "        loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calculate the per-dimension standard deviation of the outputs\n",
    "        # we can use this later to check whether the embeddings are collapsing\n",
    "        output = p0.detach()\n",
    "        output = torch.nn.functional.normalize(output, dim=1)\n",
    "\n",
    "        output_std = torch.std(output, 0)\n",
    "        output_std = output_std.mean()\n",
    "\n",
    "        # use moving averages to track the loss and standard deviation\n",
    "        w = 0.9\n",
    "        avg_loss = w * avg_loss + (1 - w) * loss.item()\n",
    "        avg_output_std = w * avg_output_std + (1 - w) * output_std.item()\n",
    "\n",
    "    # the level of collapse is large if the standard deviation of the l2\n",
    "    # normalized output is much smaller than 1 / sqrt(dim)\n",
    "    collapse_level = max(0.0, 1 - math.sqrt(out_dim) * avg_output_std)\n",
    "    # print intermediate results\n",
    "    print(\n",
    "        f\"[Epoch {e:3d}] \"\n",
    "        f\"Loss = {avg_loss:.2f} | \"\n",
    "        f\"Collapse Level: {collapse_level:.2f} / 1.00\"\n",
    "    )\n",
    "\n",
    "torch.save({'state_dict': model.state_dict()}, './SimSiam' + '/model_last.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TssUAIrqARa"
   },
   "source": [
    "# Fine-tune & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lwGkTRQXANJ"
   },
   "outputs": [],
   "source": [
    "dir_checkpoint = './fine-tune/cls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLYcJs5N0Ku4"
   },
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "  count = 0\n",
    "  for data, targets in loader:\n",
    "    data = data.to(device)\n",
    "    targets = targets[0].float().to(device)\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "      predictions = model(data)\n",
    "      loss = loss_fn(predictions, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "  return loss , data, targets, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZ-MNUGcNW1U"
   },
   "outputs": [],
   "source": [
    "def val_step(loader, model, scheduler, device=device):\n",
    "  num_correct = 0\n",
    "  num_pixels = 0\n",
    "  dice_score = 0\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      for x,y in loader:\n",
    "          #print(x.type)\n",
    "          x=x.to(device)\n",
    "          y=y[0].to(device)\n",
    "          preds = torch.sigmoid(model(x))\n",
    "          #preds = model(x)\n",
    "          preds = (preds > 0.5).float() #converts greater than 0.5 to 1 and less than 0.5 to 0\n",
    "          num_correct += (preds == y).sum()\n",
    "          num_pixels += torch.numel(preds)\n",
    "          dice_score += (2 * (preds * y).sum()) / (preds + y).sum()\n",
    "\n",
    "  #print(f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\")\n",
    "  #print(f\"Dice score: {dice_score/len(loader):.3f}\")\n",
    "  dice_score = dice_score/len(loader)\n",
    "  scheduler.step(dice_score)\n",
    "  model.train()\n",
    "  return dice_score, x, y, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztVkpArGPYP1"
   },
   "outputs": [],
   "source": [
    "def train_model1(model, epochs, batch_size, learning_rate,train_dataset, val_dataset, early_stop = False, save_checkpoint = True, device=device):\n",
    "  loss_fn = nn.BCEWithLogitsLoss()\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)\n",
    "  scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "  train_loader = data.DataLoader(train_dataset, batch_size=batch_size, pin_memory = True, shuffle=True, num_workers=NUM_WORKERS)\n",
    "  val_loader = data.DataLoader(val_dataset, batch_size=batch_size, pin_memory = True, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "  global_val_score = 0\n",
    "  global_counter=0\n",
    "  # (Initialize logging)\n",
    "  #experiment = wandb.init(project='Runs', resume='allow', anonymous='must')\n",
    "  #experiment.config.update(\n",
    "  #    dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "  #          save_checkpoint=save_checkpoint)\n",
    "  #)\n",
    "\n",
    "  n_train = len(train_dataset)\n",
    "  n_val = len(val_dataset)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "\n",
    "      #Train loop\n",
    "      loss, images, targets, predictions  = train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "      #experiment.log({\n",
    "      #              'train loss': loss.item(),\n",
    "      #              'epoch': epoch\n",
    "      #          })\n",
    "      pbar.set_postfix(**{'loss (epoch)': loss.item()})\n",
    "\n",
    "      if epoch % 5== 0:\n",
    "        #histograms = {}\n",
    "        #for tag, value in model.named_parameters():\n",
    "        #    tag = tag.replace('/', '.')\n",
    "        #    if not (torch.isinf(value) | torch.isnan(value)).any():\n",
    "        #        histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "        #    if not (torch.isinf(value.grad) | torch.isnan(value.grad)).any():\n",
    "        #        histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "        val_score, x, y, preds = val_step(val_loader,model, scheduler, device)\n",
    "        pbar.set_postfix(**{'loss (batch)': loss.item(),'Dice score (batch)': val_score})\n",
    "        predictions = (predictions > 0.5).float()\n",
    "        #try:\n",
    "        #    experiment.log({\n",
    "        #        'learning rate': optimizer.param_groups[0]['lr'],\n",
    "        #        'validation Dice': val_score,\n",
    "        #        'train images': wandb.Image(images.cpu()),\n",
    "        #        'train masks': {\n",
    "        #            'true': wandb.Image(targets.float().cpu()),\n",
    "        #            'pred': wandb.Image(predictions.cpu()),\n",
    "        #        },\n",
    "        #        'val images': wandb.Image(x.cpu()),\n",
    "        #        'val masks': {\n",
    "        #            'true': wandb.Image(y.float().cpu()),\n",
    "        #            'pred': wandb.Image(preds.cpu()),\n",
    "        #        },\n",
    "        #        'epoch': epoch,\n",
    "        #        **histograms\n",
    "        #    })\n",
    "        #except:\n",
    "        #    pass\n",
    "\n",
    "        if val_score > global_val_score:\n",
    "            if val_score - global_val_score > 0.01:\n",
    "                global_counter = 0\n",
    "                #print(\"Global_counter = 0\")\n",
    "                global_val_score  = val_score\n",
    "                if save_checkpoint == True:\n",
    "                  state_dict = model.state_dict()\n",
    "                  torch.save(state_dict, f\"{dir_checkpoint}/best_checkpoint_size{n_train}.pth\")\n",
    "                  #wandb.save(f\"{dir_checkpoint}/best_checkpoint_size{n_train}.pth\")\n",
    "            else:\n",
    "                global_counter+=1\n",
    "                #print(\"Global_counter = \", global_counter)\n",
    "        else:\n",
    "            global_counter+= 1\n",
    "            #print(\"Global_counter = \", global_counter)\n",
    "\n",
    "        if global_counter == 5 and early_stop == True:\n",
    "            print(\"Val score didn´t change for 5 validation iterations\")\n",
    "            break\n",
    "\n",
    "  #torch.save(state_dict, f\"{dir_checkpoint}/edntrain_checkpoint_valscore{val_score}.pth\")\n",
    "  #wandb.save(f\"{dir_checkpoint}/edntrain_checkpoint_valscore{val_score}.pth\")\n",
    "  #wandb.finish()\n",
    "  model.load_state_dict(torch.load(f\"{dir_checkpoint}/best_checkpoint_size{n_train}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHFkcgpNqARa"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, device=device):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            #print(x.type)\n",
    "            x=x.to(device)\n",
    "            y=y[0].to(device)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            #preds = model(x)\n",
    "            preds = (preds > 0.5).float() #converts greater than 0.5 to 1 and less than 0.5 to 0\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "            dice_score += (2 * (preds * y).sum()) / (preds + y).sum()\n",
    "\n",
    "    print(f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\")\n",
    "    print(f\"Dice score: {dice_score/len(loader):.2f}\")\n",
    "    model.train()\n",
    "    return dice_score/len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irhWIe47VkTY"
   },
   "outputs": [],
   "source": [
    "test_loader = data.DataLoader(test_dataset, batch_size = 32, shuffle=False, pin_memory=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"DC-100%\":[],\"DC-50%\":[],\"DC-25%\":[],\"DC-10%\":[]}\n",
    "my_list = []\n",
    "label = \"ResNet-ImageNetMini\"\n",
    "checkpoint=torch.load('/home/hugo-figueiras/Documents/Trained Models-64/U-Net/SimSiam/BUS/model_last.pth')\n",
    "for y in range(10):\n",
    "        for x in range(4):\n",
    "            model = SimSiam(backbone, num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim)\n",
    "            model.backbone.outc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten()\n",
    "            )\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            model.backbone.outc = OutConv(64,1)\n",
    "            unet = model.backbone\n",
    "            unet.to(device)\n",
    "\n",
    "            if x == 0:\n",
    "                train_dataset_div = train_dataset\n",
    "                key = \"DC-100%\"\n",
    "            elif x == 1:\n",
    "                train_dataset_div, train_dataset_discard = torch.utils.data.random_split(train_dataset, [0.5,0.5])\n",
    "                key = \"DC-50%\"\n",
    "            elif x==2:\n",
    "                train_dataset_div, train_dataset_discard = torch.utils.data.random_split(train_dataset, [0.25,0.75])\n",
    "                key = \"DC-25%\"\n",
    "            elif x==3:\n",
    "                train_dataset_div, train_dataset_discard = torch.utils.data.random_split(train_dataset, [0.10,0.90])\n",
    "                key = \"DC-10%\"\n",
    "\n",
    "            train_model1(unet, 3000, 256, 1e-4, train_dataset_div, val_dataset, True)\n",
    "            dice_score = check_accuracy(test_loader, unet, device=device)\n",
    "            dc = \"{:.2f}\".format(dice_score.item())\n",
    "            my_dict[key].append(f\"{dc}\")\n",
    "            string = f\"serie: {y} | Iteration: {x} | DC: {dice_score.item():.2f}\"\n",
    "            my_list.append(string)\n",
    "            print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMSGlW3ETya_",
    "outputId": "9e13df86-2b6f-4608-f6b5-abf1fcd633d5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_dict = {\"DC-100%\":[],\"DC-50%\":[],\"DC-25%\":[],\"DC-10%\":[]}\n",
    "my_list = []\n",
    "\n",
    "\n",
    "#unet_backbone = SimCLR.load_from_checkpoint('/home/hugo-figueiras/Documents/Trained Models/SimCLR/ResNet50-size32/lightning_logs/version_0/checkpoints/epoch=1183-step=11840.ckpt')\n",
    "label = \"SimCLR-ImageNet-UNet\"\n",
    "checkpoint='./Trained Models-64/U-Net/SimCLR/SimCLR-ImageNet+BUS/checkpoints/epoch=164-step=31350.ckpt'\n",
    "\n",
    "for y in range(10):\n",
    "    for x in range(4): \n",
    "        model = SimCLR1.load_from_checkpoint(checkpoint)\n",
    "        model.convnet.outc = OutConv(64,1)\n",
    "        unet = model.convnet\n",
    "        unet.to(device)\n",
    "\n",
    "        if x == 0:\n",
    "            train_dataset_div = train_dataset\n",
    "            key = \"DC-100%\"\n",
    "        elif x == 1:\n",
    "            train_dataset_div, train_dataset_discard = torch.utils.data.random_split(train_dataset, [0.5,0.5])\n",
    "            key = \"DC-50%\"\n",
    "        elif x==2:\n",
    "            train_dataset_div, train_dataset_discard = torch.utils.data.random_split(train_dataset, [0.25,0.75])\n",
    "            key = \"DC-25%\"\n",
    "        elif x==3:\n",
    "            train_dataset_div, train_dataset_discard = torch.utils.data.random_split(train_dataset, [0.10,0.90])\n",
    "            key = \"DC-10%\"\n",
    "\n",
    "        train_model1(unet, 3000, 32, 1e-4, train_dataset_div, val_dataset, True)\n",
    "        dice_score = check_accuracy(test_loader, unet, device=device)\n",
    "        dc = \"{:.2f}\".format(dice_score.item())\n",
    "        my_dict[key].append(f\"{dc}\")\n",
    "        string = f\"serie: {y} | Iteration: {x} | DC: {dice_score.item():.2f}\"\n",
    "        my_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in my_dict[\"DC-100%\"]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in my_dict[\"DC-50%\"]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in my_dict[\"DC-25%\"]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in my_dict[\"DC-10%\"]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WvsFIJLqARa"
   },
   "outputs": [],
   "source": [
    "def save_predictions_as_imgs(loader, model, folder, device):\n",
    "    model.eval()\n",
    "    for idx, (x,y) in enumerate(loader):\n",
    "        #print(x)\n",
    "        x = x.to(device=device)\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "        #print(len(loader))\n",
    "        torchvision.utils.save_image(preds, f\"{folder}/preds_{idx}.png\")\n",
    "        torchvision.utils.save_image(y[0], f\"{folder}/masks_{idx}.png\")\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_img(image, model, folder, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = torch.sigmoid(model(image))\n",
    "        preds = (preds > 0.5).float()\n",
    "    #print(len(loader))\n",
    "    torchvision.utils.save_image(preds, f\"{folder}/preds_final.png\")\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2AsO4mFqARb"
   },
   "outputs": [],
   "source": [
    "checkpoint=torch.load('./Trained Models-64/U-Net/SimSiam/BUS/model_last.pth')\n",
    "model = ModelMoCo(\n",
    "        dim=args.moco_dim,\n",
    "        K=args.moco_k,\n",
    "        m=args.moco_m,\n",
    "        T=args.moco_t,\n",
    "        arch=args.arch,\n",
    "        bn_splits=args.bn_splits,\n",
    "        symmetric=args.symmetric,\n",
    "    )\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.backbone.outc = OutConv(64,1)\n",
    "unet = model.backbone\n",
    "unet.to(device)\n",
    "\n",
    "train_model1(unet, 3000, 32, 1e-4, train_dataset, val_dataset, True)\n",
    "\n",
    "save_predictions_as_imgs(test_loader, unet,\"./saved_images\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Maps Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelMoCo(\n",
    "        dim=args.moco_dim,\n",
    "        K=args.moco_k,\n",
    "        m=args.moco_m,\n",
    "        T=args.moco_t,\n",
    "        arch=args.arch,\n",
    "        bn_splits=args.bn_splits,\n",
    "        symmetric=args.symmetric,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./Trained Models-64/ResNet50/MoCo/MoCo-BUS/model_best.pth')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = model.encoder_q\n",
    "model = UNetWithResnet50Encoder(resnet)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ('/home/hugo-figueiras/Documents/Trained Models-64/ResNet50/SimCLR/SimCLR-ImageNetMini/checkpoints/epoch=247-step=46624.ckpt')\n",
    "resnet = SimCLR1.load_from_checkpoint(checkpoint)\n",
    "resnet = resnet.convnet\n",
    "model = UNetWithResnet50Encoder(resnet)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./Trained Models-32/ResNet50/SimSiam/Multi/model_last.pth')\n",
    "resnet = torchvision.models.resnet50()\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "sim = SimSiam(backbone, num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim)\n",
    "sim.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "resnet = sim.backbone\n",
    "\n",
    "model = UNetWithResnet50Encoder(resnet)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet50()\n",
    "model = UNetWithResnet50Encoder(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = Image.open(str('/home/hugo-figueiras/Documents/Feature_maps_imgs/benign (83)_mask.png'))\n",
    "image1 = img_transforms_ultra(image1)\n",
    "save_image(image1, './input_imgs/size_50/double_img_mask.png')\n",
    "print(f\"Image shape before: {image1.shape}\")\n",
    "image1 = image1.unsqueeze(0)\n",
    "print(f\"Image shape after: {image1.shape}\")\n",
    "image1 = image1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "names = []\n",
    "for layer in conv_layers[0:]:\n",
    "    image = layer(image)\n",
    "    outputs.append(image)\n",
    "    names.append(str(layer))\n",
    "print(len(outputs))\n",
    "#print feature_maps\n",
    "for feature_map in outputs:\n",
    "    print(feature_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []\n",
    "for feature_map in outputs:\n",
    "    feature_map = feature_map.squeeze(0)\n",
    "    gray_scale = torch.sum(feature_map,0)\n",
    "    gray_scale = gray_scale / feature_map.shape[0]\n",
    "    processed.append(gray_scale.data.cpu().numpy())\n",
    "for fm in processed:\n",
    "    print(fm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 50))\n",
    "for i in range(len(processed)):\n",
    "    try:\n",
    "        a = fig.add_subplot(5, 4, i+1)\n",
    "        imgplot = plt.imshow(processed[i])\n",
    "        a.axis(\"off\")\n",
    "        a.set_title(names[i].split('(')[0], fontsize=30)\n",
    "    except ValueError:\n",
    "        break\n",
    "plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model1(model, 3000, 32, 1e-4, train_dataset, val_dataset, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prediction_img(image4, model,\"./\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "layer = model.input_block[0]\n",
    "weights = model.input_block[0].weight\n",
    "\n",
    "outputs.append(layer(image4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []\n",
    "for feature_map in outputs:\n",
    "    feature_map = feature_map.squeeze(0)\n",
    "    gray_scale = torch.sum(feature_map,0)\n",
    "    gray_scale = gray_scale / feature_map.shape[0]\n",
    "    processed.append(gray_scale.data.cpu().numpy())\n",
    "for fm in processed:\n",
    "    print(fm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 50))\n",
    "for i in range(len(processed)):\n",
    "    try:\n",
    "        a = fig.add_subplot(5, 4, i+1)\n",
    "        imgplot = plt.imshow(processed[i])\n",
    "        a.axis(\"off\")\n",
    "    except ValueError:\n",
    "        break\n",
    "plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DiXgJ8CzqARO",
    "W4zBGlH2xBwD",
    "1XDMAXg1HWhP",
    "nC44sDfpE6Ku"
   ],
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
